{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":13294,"status":"ok","timestamp":1672401208022,"user":{"displayName":"邱奕傑","userId":"13446123829054950802"},"user_tz":-480},"id":"fTnVd_nOkiXG"},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-01-18 23:33:05.870738: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-01-18 23:33:10.938975: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n","2023-01-18 23:33:10.951635: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n","2023-01-18 23:33:10.951684: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"]}],"source":["import os\n","import time\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","\n","from tensorflow.keras.layers import Masking, Bidirectional, LSTM, TimeDistributed, Dense, Activation, BatchNormalization\n","from tensorflow.keras.regularizers import L2\n","\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":286,"status":"ok","timestamp":1672401210623,"user":{"displayName":"邱奕傑","userId":"13446123829054950802"},"user_tz":-480},"id":"nTjmuCsqkiXJ"},"outputs":[],"source":["EXPERIMENT_TITLE = \"15_BDLSTM_Transfer2/\"\n","EXPERIMENT_DIR = \"experiments/\" + EXPERIMENT_TITLE\n","\n","BATCH_SIZE = 4096\n","PIECE_LEN = 128\n","n_feature = 43\n","n_hidden = 100\n","n_pitch = 53\n","learning_rate = 0.001"]},{"cell_type":"markdown","metadata":{"id":"7z3W1cF8kiXK"},"source":["## build dataset"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":24,"status":"ok","timestamp":1672401213295,"user":{"displayName":"邱奕傑","userId":"13446123829054950802"},"user_tz":-480},"id":"Wzc45h8SkiXM"},"outputs":[],"source":["def load_npy_data(x_path, y_path, offset):\n","    x = np.load(x_path)\n","    y = np.load(y_path)\n","    if x.shape[0] >= offset+PIECE_LEN:\n","        return x[offset:offset+PIECE_LEN].astype(np.float64), y[offset:offset+PIECE_LEN].astype(np.float64)\n","    else:\n","        pad_count = offset + PIECE_LEN - x.shape[0]\n","        x = np.pad(x[offset:], ((0, pad_count), (0, 0)), 'constant', constant_values=-1).astype(np.float64)\n","        y = np.pad(y[offset:], ((0, pad_count), (0, 0)), 'constant', constant_values=-1).astype(np.float64)\n","        return x, y\n","\n","def generate_dataset(input_dir: str):\n","    x_paths = []\n","    y_paths = []\n","    offsets = []\n","    for file_name in sorted(os.listdir(input_dir)):\n","        if file_name.endswith(\".ans.npy\"):\n","            y_path = str(os.path.join(input_dir, file_name))\n","            x_path = str(os.path.join(input_dir, file_name.replace(\".ans.npy\", \".npy\")))\n","            assert os.path.exists(x_path), f\"corresponding input file {x_path} doesn't exist\"\n","            y_content = np.load(y_path)\n","            for offset in range(0, y_content.shape[0], PIECE_LEN):\n","                y_paths.append(y_path)\n","                x_paths.append(x_path)\n","                offsets.append(offset)\n","\n","    \n","    train_dataset = tf.data.Dataset.from_tensor_slices((x_paths, y_paths, offsets)).shuffle(100000)\n","    train_dataset = train_dataset.map(lambda x_path, y_path, offset: tf.numpy_function(load_npy_data, [x_path, y_path, offset], [tf.float64, tf.float64]))\n","    train_dataset = train_dataset.batch(BATCH_SIZE).prefetch(-1).cache()\n","    \n","    return train_dataset"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"afVoKJKK1QvD"},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-01-18 23:33:49.109433: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-18 23:33:49.156135: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-18 23:33:49.156758: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-18 23:33:49.172277: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-01-18 23:33:49.174157: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-18 23:33:49.174737: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-18 23:33:49.175237: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-18 23:33:52.461476: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-18 23:33:52.469106: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-18 23:33:52.469705: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-18 23:33:52.476442: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10397 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n"]},{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:From /media/labhdd/cyc/miniconda3/envs/p3-10/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n","Instructions for updating:\n","Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"]}],"source":["easy_dataset = generate_dataset(\"./preprocessed_dataset/irealpro_dataset_v2_simple/\")\n","# train_dataset = generate_dataset(\"preprocessed_dataset/augmentation_v2_simple\")\n","validation_dataset = generate_dataset(\"preprocessed_dataset/midkar_v2_simple\")"]},{"cell_type":"markdown","metadata":{"id":"EFZe6EfvkiXN"},"source":["## build model"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5723,"status":"ok","timestamp":1672401222694,"user":{"displayName":"邱奕傑","userId":"13446123829054950802"},"user_tz":-480},"id":"XLjpnzwTkiXO","outputId":"290c68af-8c74-43d7-83b4-bec22a85f6f4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 128, 43)]         0         \n","                                                                 \n"," mask (Masking)              (None, 128, 43)           0         \n","                                                                 \n"," input (TimeDistributed)     (None, 128, 100)          4400      \n","                                                                 \n"," bidirectional (Bidirectiona  (None, 128, 200)         160800    \n"," l)                                                              \n","                                                                 \n"," output (TimeDistributed)    (None, 128, 53)           10653     \n","                                                                 \n","=================================================================\n","Total params: 175,853\n","Trainable params: 175,853\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"]}],"source":["# print(\"Creating model\")\n","input = tf.keras.Input(shape=(PIECE_LEN, n_feature))  \n","x = Masking(mask_value=-1, input_shape=(PIECE_LEN, n_feature), name=\"mask\")(input) # Ignore Padded Data\n","x = TimeDistributed(Dense(n_hidden, activation=\"relu\", input_shape=(1, n_feature), kernel_regularizer=L2(0.001)), name=\"input\")(x)\n","x = Bidirectional(tf.keras.layers.LSTM(units=n_hidden, input_shape=(1, n_feature), return_sequences=True, kernel_regularizer=L2(0.0001), recurrent_regularizer=L2(0.0001)))(x)\n","x = TimeDistributed(Dense(n_pitch, activation=\"softmax\", kernel_regularizer=L2(0.001)), name=\"output\")(x)\n","model = tf.keras.Model(inputs=input, outputs=x)\n","print(model.summary())\n","optimizer=tf.keras.optimizers.experimental.Nadam(learning_rate=learning_rate)\n","# optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate)"]},{"cell_type":"markdown","metadata":{"id":"6MdoyCeYkiXQ"},"source":["## loss/accuracy function"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1672401222696,"user":{"displayName":"邱奕傑","userId":"13446123829054950802"},"user_tz":-480},"id":"x7-3osy8kiXR"},"outputs":[],"source":["@tf.function\n","def masked_loss_function(y_true, y_pred):\n","    mask = tf.math.not_equal(tf.reduce_sum(y_true, axis=2), -1*n_pitch)\n","    loss = tf.losses.categorical_crossentropy(y_true, y_pred)\n","    mask = tf.cast(mask, loss.dtype)\n","    loss *= mask\n","    return tf.reduce_mean(loss)\n","\n","@tf.function\n","def masked_accuracy(y_true, y_pred):\n","    mask = tf.math.not_equal(tf.reduce_sum(y_true, axis=2), -1*n_pitch)\n","    acc = tf.metrics.categorical_accuracy(y_true, y_pred)\n","    mask = tf.cast(mask, acc.dtype)\n","    acc *= mask\n","    return tf.reduce_mean(acc)"]},{"cell_type":"markdown","metadata":{"id":"f4ozM0e4DgdM"},"source":["### restore checkpoint"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"R7299W7uBURJ"},"outputs":[],"source":["checkpoint_dir = './checkpoints/' + EXPERIMENT_TITLE\n","checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n","checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n","                                 model=model)"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":431,"status":"ok","timestamp":1672389872176,"user":{"displayName":"邱奕傑","userId":"13446123829054950802"},"user_tz":-480},"id":"8tzFhMQPBXY6","outputId":"67341b04-4dad-47da-9258-c558a187d0f3"},"outputs":[{"data":{"text/plain":["<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f7ff0595540>"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["# checkpoint.restore(checkpoint_prefix+\"-1\")"]},{"cell_type":"markdown","metadata":{"id":"UmmelpaBkiXS"},"source":["## training"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":393,"status":"ok","timestamp":1672401230272,"user":{"displayName":"邱奕傑","userId":"13446123829054950802"},"user_tz":-480},"id":"rhWVti6IkiXU"},"outputs":[],"source":["@tf.function\n","def train_step(x, y):\n","    loss = 0\n","    with tf.GradientTape() as tape:\n","        pred = model(x)\n","        \n","        loss = masked_loss_function(y, pred)\n","        weight_decay = tf.reduce_sum(model.losses)\n","        loss += weight_decay\n","\n","    gradients = tape.gradient(loss, model.trainable_variables)\n","    gradients = [(tf.clip_by_value(grad, clip_value_min=-1.0, clip_value_max=1.0)) for grad in gradients]\n","\n","    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n","    acc = masked_accuracy(y, pred)\n","\n","    return loss, acc"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["@tf.function\n","def val_step(x, y):\n","    pred = model(x)\n","    loss = masked_loss_function(y, pred)\n","    weight_decay = tf.reduce_sum(model.losses)\n","    loss += weight_decay\n","    acc = masked_accuracy(y, pred)\n","    return loss, acc"]},{"cell_type":"markdown","metadata":{},"source":["### stage 1"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["loss_history = []\n","val_loss_history = []\n","acc_history = []\n","val_acc_history = []\n","# loss_history = np.load(EXPERIMENT_DIR+\"/loss_history.npy\")\n","# acc_history = np.load(EXPERIMENT_DIR+\"/acc_history.npy\")\n","# val_loss_history = np.load(EXPERIMENT_DIR+\"/val_loss_history.npy\")\n","# val_acc_history = np.load(EXPERIMENT_DIR+\"/val_acc_history.npy\")\n","# loss_history = np.load(\"experiments/BDLSTM_simple/history.npy\").tolist()"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":584744,"status":"error","timestamp":1672388158237,"user":{"displayName":"邱奕傑","userId":"13446123829054950802"},"user_tz":-480},"id":"MCXNL-sFkiXV","outputId":"5f268219-ecad-4ac1-c055-c41c218ec0e5"},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-01-18 23:34:44.779703: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n","type_id: TFT_OPTIONAL\n","args {\n","  type_id: TFT_PRODUCT\n","  args {\n","    type_id: TFT_TENSOR\n","    args {\n","      type_id: TFT_INT32\n","    }\n","  }\n","}\n"," is neither a subtype nor a supertype of the combined inputs preceding it:\n","type_id: TFT_OPTIONAL\n","args {\n","  type_id: TFT_PRODUCT\n","  args {\n","    type_id: TFT_TENSOR\n","    args {\n","      type_id: TFT_FLOAT\n","    }\n","  }\n","}\n","\n","\twhile inferring type of node 'cond_20/output/_23'\n","2023-01-18 23:34:45.841291: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8201\n","2023-01-18 23:34:46.846427: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7f34d0017270 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2023-01-18 23:34:46.846511: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1\n","2023-01-18 23:34:47.357029: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n","2023-01-18 23:34:49.131308: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:109] You are using ptxas 8.x, but TF requires ptxas 9.x (and strongly prefers >= 11.1).  Compilation of XLA kernels below will likely fail.\n","\n","You may not need to update CUDA; cherry-picking the ptxas binary is often sufficient.\n","2023-01-18 23:34:49.166993: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:234] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 6.1\n","2023-01-18 23:34:49.167030: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:237] Used ptxas at ptxas\n","2023-01-18 23:34:49.175012: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","2023-01-18 23:34:49.325722: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:109] You are using ptxas 8.x, but TF requires ptxas 9.x (and strongly prefers >= 11.1).  Compilation of XLA kernels below will likely fail.\n","\n","You may not need to update CUDA; cherry-picking the ptxas binary is often sufficient.\n","2023-01-18 23:34:49.434772: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:109] You are using ptxas 8.x, but TF requires ptxas 9.x (and strongly prefers >= 11.1).  Compilation of XLA kernels below will likely fail.\n","\n","You may not need to update CUDA; cherry-picking the ptxas binary is often sufficient.\n","2023-01-18 23:34:49.621175: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:109] You are using ptxas 8.x, but TF requires ptxas 9.x (and strongly prefers >= 11.1).  Compilation of XLA kernels below will likely fail.\n","\n","You may not need to update CUDA; cherry-picking the ptxas binary is often sufficient.\n","2023-01-18 23:34:49.738113: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:109] You are using ptxas 8.x, but TF requires ptxas 9.x (and strongly prefers >= 11.1).  Compilation of XLA kernels below will likely fail.\n","\n","You may not need to update CUDA; cherry-picking the ptxas binary is often sufficient.\n","2023-01-18 23:34:49.849973: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:109] You are using ptxas 8.x, but TF requires ptxas 9.x (and strongly prefers >= 11.1).  Compilation of XLA kernels below will likely fail.\n","\n","You may not need to update CUDA; cherry-picking the ptxas binary is often sufficient.\n","2023-01-18 23:34:50.008746: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:109] You are using ptxas 8.x, but TF requires ptxas 9.x (and strongly prefers >= 11.1).  Compilation of XLA kernels below will likely fail.\n","\n","You may not need to update CUDA; cherry-picking the ptxas binary is often sufficient.\n","2023-01-18 23:34:50.126590: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:109] You are using ptxas 8.x, but TF requires ptxas 9.x (and strongly prefers >= 11.1).  Compilation of XLA kernels below will likely fail.\n","\n","You may not need to update CUDA; cherry-picking the ptxas binary is often sufficient.\n","2023-01-18 23:34:50.235643: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:109] You are using ptxas 8.x, but TF requires ptxas 9.x (and strongly prefers >= 11.1).  Compilation of XLA kernels below will likely fail.\n","\n","You may not need to update CUDA; cherry-picking the ptxas binary is often sufficient.\n","2023-01-18 23:34:50.340594: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:109] You are using ptxas 8.x, but TF requires ptxas 9.x (and strongly prefers >= 11.1).  Compilation of XLA kernels below will likely fail.\n","\n","You may not need to update CUDA; cherry-picking the ptxas binary is often sufficient.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1 Loss 3.6489 Acc 0.0822\n","Validation Loss 3.5692 Acc 0.1055\n","Time taken for 1 epoch 80.34869360923767 sec\n","\n","Epoch 2 Loss 3.0148 Acc 0.1818\n","Validation Loss 3.5226 Acc 0.1528\n","Time taken for 1 epoch 5.332726716995239 sec\n","\n","Epoch 3 Loss 2.7952 Acc 0.2121\n","Validation Loss 3.5426 Acc 0.1632\n","Time taken for 1 epoch 5.367612361907959 sec\n","\n","Epoch 4 Loss 2.6813 Acc 0.2319\n","Validation Loss 3.5975 Acc 0.1643\n","Time taken for 1 epoch 5.3262622356414795 sec\n","\n","Epoch 5 Loss 2.6069 Acc 0.2461\n","Validation Loss 3.6115 Acc 0.1628\n","Time taken for 1 epoch 5.340776443481445 sec\n","\n","Epoch 6 Loss 2.5533 Acc 0.2568\n","Validation Loss 3.6049 Acc 0.1620\n","Time taken for 1 epoch 5.422240495681763 sec\n","\n","Epoch 7 Loss 2.5108 Acc 0.2652\n","Validation Loss 3.5968 Acc 0.1609\n","Time taken for 1 epoch 5.377564430236816 sec\n","\n","Epoch 8 Loss 2.4761 Acc 0.2722\n","Validation Loss 3.5932 Acc 0.1602\n","Time taken for 1 epoch 5.428133010864258 sec\n","\n","Epoch 9 Loss 2.4468 Acc 0.2780\n","Validation Loss 3.5861 Acc 0.1597\n","Time taken for 1 epoch 5.390653610229492 sec\n","\n","Epoch 10 Loss 2.4212 Acc 0.2831\n","Validation Loss 3.5838 Acc 0.1595\n","Time taken for 1 epoch 5.42213773727417 sec\n","\n","Epoch 11 Loss 2.3979 Acc 0.2880\n","Validation Loss 3.5769 Acc 0.1580\n","Time taken for 1 epoch 5.364761590957642 sec\n","\n","Epoch 12 Loss 2.3763 Acc 0.2928\n","Validation Loss 3.5766 Acc 0.1580\n","Time taken for 1 epoch 5.364170789718628 sec\n","\n","Epoch 13 Loss 2.3562 Acc 0.2972\n","Validation Loss 3.5836 Acc 0.1575\n","Time taken for 1 epoch 5.406705856323242 sec\n","\n","Epoch 14 Loss 2.3375 Acc 0.3014\n","Validation Loss 3.5760 Acc 0.1583\n","Time taken for 1 epoch 5.409255504608154 sec\n","\n","Epoch 15 Loss 2.3217 Acc 0.3046\n","Validation Loss 3.5788 Acc 0.1610\n","Time taken for 1 epoch 5.398235559463501 sec\n","\n","Epoch 16 Loss 2.3043 Acc 0.3086\n","Validation Loss 3.5668 Acc 0.1626\n","Time taken for 1 epoch 5.3992321491241455 sec\n","\n","Epoch 17 Loss 2.2881 Acc 0.3123\n","Validation Loss 3.5747 Acc 0.1633\n","Time taken for 1 epoch 5.40420937538147 sec\n","\n","Epoch 18 Loss 2.2753 Acc 0.3148\n","Validation Loss 3.5750 Acc 0.1629\n","Time taken for 1 epoch 5.442906141281128 sec\n","\n","Epoch 19 Loss 2.2586 Acc 0.3188\n","Validation Loss 3.5817 Acc 0.1589\n","Time taken for 1 epoch 5.3933117389678955 sec\n","\n","Epoch 20 Loss 2.2481 Acc 0.3209\n","Validation Loss 3.5717 Acc 0.1643\n","Time taken for 1 epoch 5.375800609588623 sec\n","\n","Epoch 21 Loss 2.2306 Acc 0.3251\n","Validation Loss 3.5774 Acc 0.1656\n","Time taken for 1 epoch 5.456169605255127 sec\n","\n","Epoch 22 Loss 2.2232 Acc 0.3261\n","Validation Loss 3.5983 Acc 0.1586\n","Time taken for 1 epoch 5.416736125946045 sec\n","\n","Epoch 23 Loss 2.2090 Acc 0.3298\n","Validation Loss 3.5739 Acc 0.1653\n","Time taken for 1 epoch 5.389141321182251 sec\n","\n","Epoch 24 Loss 2.1981 Acc 0.3322\n","Validation Loss 3.5918 Acc 0.1663\n","Time taken for 1 epoch 5.42405366897583 sec\n","\n","Epoch 25 Loss 2.1870 Acc 0.3347\n","Validation Loss 3.5835 Acc 0.1673\n","Time taken for 1 epoch 5.373851299285889 sec\n","\n","Epoch 26 Loss 2.1818 Acc 0.3355\n","Validation Loss 3.5932 Acc 0.1640\n","Time taken for 1 epoch 5.416126489639282 sec\n","\n","Epoch 27 Loss 2.1707 Acc 0.3382\n","Validation Loss 3.5863 Acc 0.1678\n","Time taken for 1 epoch 5.4186224937438965 sec\n","\n","Epoch 28 Loss 2.1623 Acc 0.3401\n","Validation Loss 3.5860 Acc 0.1689\n","Time taken for 1 epoch 5.453466176986694 sec\n","\n","Epoch 29 Loss 2.1523 Acc 0.3423\n","Validation Loss 3.6067 Acc 0.1640\n","Time taken for 1 epoch 5.408229351043701 sec\n","\n","Epoch 30 Loss 2.1525 Acc 0.3418\n","Validation Loss 3.5971 Acc 0.1675\n","Time taken for 1 epoch 5.414341688156128 sec\n","\n","Epoch 31 Loss 2.1386 Acc 0.3454\n","Validation Loss 3.5872 Acc 0.1672\n","Time taken for 1 epoch 5.416955471038818 sec\n","\n","Epoch 32 Loss 2.1354 Acc 0.3457\n","Validation Loss 3.6018 Acc 0.1694\n","Time taken for 1 epoch 5.454343795776367 sec\n","\n","Epoch 33 Loss 2.1251 Acc 0.3482\n","Validation Loss 3.6030 Acc 0.1646\n","Time taken for 1 epoch 5.421396970748901 sec\n","\n","Epoch 34 Loss 2.1247 Acc 0.3481\n","Validation Loss 3.5914 Acc 0.1682\n","Time taken for 1 epoch 5.432247877120972 sec\n","\n","Epoch 35 Loss 2.1129 Acc 0.3507\n","Validation Loss 3.6141 Acc 0.1681\n","Time taken for 1 epoch 5.401750564575195 sec\n","\n","Epoch 36 Loss 2.1124 Acc 0.3504\n","Validation Loss 3.5970 Acc 0.1700\n","Time taken for 1 epoch 5.394591569900513 sec\n","\n","Epoch 37 Loss 2.1027 Acc 0.3529\n","Validation Loss 3.6032 Acc 0.1664\n","Time taken for 1 epoch 5.4167258739471436 sec\n","\n","Epoch 38 Loss 2.1003 Acc 0.3532\n","Validation Loss 3.6121 Acc 0.1701\n","Time taken for 1 epoch 5.450695991516113 sec\n","\n","Epoch 39 Loss 2.0933 Acc 0.3547\n","Validation Loss 3.6160 Acc 0.1662\n","Time taken for 1 epoch 5.421535491943359 sec\n","\n","Epoch 40 Loss 2.0919 Acc 0.3547\n","Validation Loss 3.6068 Acc 0.1692\n","Time taken for 1 epoch 5.438124418258667 sec\n","\n","Epoch 41 Loss 2.0839 Acc 0.3568\n","Validation Loss 3.6169 Acc 0.1674\n","Time taken for 1 epoch 5.415390729904175 sec\n","\n","Epoch 42 Loss 2.0849 Acc 0.3561\n","Validation Loss 3.6074 Acc 0.1695\n","Time taken for 1 epoch 5.45453405380249 sec\n","\n","Epoch 43 Loss 2.0771 Acc 0.3580\n","Validation Loss 3.6350 Acc 0.1673\n","Time taken for 1 epoch 5.415782690048218 sec\n","\n","Epoch 44 Loss 2.0739 Acc 0.3586\n","Validation Loss 3.6129 Acc 0.1702\n","Time taken for 1 epoch 5.520174741744995 sec\n","\n","Epoch 45 Loss 2.0694 Acc 0.3595\n","Validation Loss 3.6155 Acc 0.1663\n","Time taken for 1 epoch 5.4304115772247314 sec\n","\n","Epoch 46 Loss 2.0664 Acc 0.3599\n","Validation Loss 3.6302 Acc 0.1698\n","Time taken for 1 epoch 5.403142929077148 sec\n","\n","Epoch 47 Loss 2.0612 Acc 0.3612\n","Validation Loss 3.6152 Acc 0.1686\n","Time taken for 1 epoch 5.444026470184326 sec\n","\n","Epoch 48 Loss 2.0650 Acc 0.3599\n","Validation Loss 3.6266 Acc 0.1679\n","Time taken for 1 epoch 5.444009304046631 sec\n","\n","Epoch 49 Loss 2.0547 Acc 0.3627\n","Validation Loss 3.6142 Acc 0.1707\n","Time taken for 1 epoch 5.397088289260864 sec\n","\n","Epoch 50 Loss 2.0519 Acc 0.3630\n","Validation Loss 3.6433 Acc 0.1673\n","Time taken for 1 epoch 5.417606592178345 sec\n","\n","Epoch 51 Loss 2.0523 Acc 0.3627\n","Validation Loss 3.6255 Acc 0.1709\n","Time taken for 1 epoch 5.674185037612915 sec\n","\n","Epoch 52 Loss 2.0445 Acc 0.3645\n","Validation Loss 3.6187 Acc 0.1698\n","Time taken for 1 epoch 5.426070690155029 sec\n","\n","Epoch 53 Loss 2.0446 Acc 0.3643\n","Validation Loss 3.6305 Acc 0.1702\n","Time taken for 1 epoch 5.422840356826782 sec\n","\n","Epoch 54 Loss 2.0389 Acc 0.3656\n","Validation Loss 3.6363 Acc 0.1686\n","Time taken for 1 epoch 5.457747220993042 sec\n","\n","Epoch 55 Loss 2.0404 Acc 0.3652\n","Validation Loss 3.6145 Acc 0.1702\n","Time taken for 1 epoch 5.473368406295776 sec\n","\n","Epoch 56 Loss 2.0367 Acc 0.3659\n","Validation Loss 3.6421 Acc 0.1685\n","Time taken for 1 epoch 5.38884425163269 sec\n","\n","Epoch 57 Loss 2.0360 Acc 0.3660\n","Validation Loss 3.6273 Acc 0.1719\n","Time taken for 1 epoch 5.436188459396362 sec\n","\n","Epoch 58 Loss 2.0296 Acc 0.3674\n","Validation Loss 3.6518 Acc 0.1671\n","Time taken for 1 epoch 5.432775497436523 sec\n","\n","Epoch 59 Loss 2.0303 Acc 0.3671\n","Validation Loss 3.6167 Acc 0.1711\n","Time taken for 1 epoch 5.462135553359985 sec\n","\n","Epoch 60 Loss 2.0241 Acc 0.3686\n","Validation Loss 3.6392 Acc 0.1689\n","Time taken for 1 epoch 5.450441122055054 sec\n","\n","Epoch 61 Loss 2.0256 Acc 0.3680\n","Validation Loss 3.6360 Acc 0.1720\n","Time taken for 1 epoch 5.43477725982666 sec\n","\n","Epoch 62 Loss 2.0197 Acc 0.3695\n","Validation Loss 3.6417 Acc 0.1680\n","Time taken for 1 epoch 5.450706720352173 sec\n","\n","Epoch 63 Loss 2.0203 Acc 0.3692\n","Validation Loss 3.6193 Acc 0.1725\n","Time taken for 1 epoch 5.452277183532715 sec\n","\n","Epoch 64 Loss 2.0181 Acc 0.3696\n","Validation Loss 3.6441 Acc 0.1689\n","Time taken for 1 epoch 5.487454891204834 sec\n","\n","Epoch 65 Loss 2.0140 Acc 0.3706\n","Validation Loss 3.6286 Acc 0.1722\n","Time taken for 1 epoch 5.408638954162598 sec\n","\n","Epoch 66 Loss 2.0132 Acc 0.3705\n","Validation Loss 3.6326 Acc 0.1680\n","Time taken for 1 epoch 5.423679351806641 sec\n","\n","Epoch 67 Loss 2.0126 Acc 0.3706\n","Validation Loss 3.6338 Acc 0.1710\n","Time taken for 1 epoch 5.444218873977661 sec\n","\n","Epoch 68 Loss 2.0086 Acc 0.3715\n","Validation Loss 3.6525 Acc 0.1702\n","Time taken for 1 epoch 5.49013090133667 sec\n","\n","Epoch 69 Loss 2.0087 Acc 0.3716\n","Validation Loss 3.6242 Acc 0.1709\n","Time taken for 1 epoch 5.426387071609497 sec\n","\n","Epoch 70 Loss 2.0039 Acc 0.3729\n","Validation Loss 3.6506 Acc 0.1683\n","Time taken for 1 epoch 5.436451196670532 sec\n","\n","Epoch 71 Loss 2.0058 Acc 0.3722\n","Validation Loss 3.6386 Acc 0.1732\n","Time taken for 1 epoch 5.39172101020813 sec\n","\n","Epoch 72 Loss 2.0012 Acc 0.3733\n","Validation Loss 3.6517 Acc 0.1667\n","Time taken for 1 epoch 5.39306378364563 sec\n","\n","Epoch 73 Loss 2.0019 Acc 0.3728\n","Validation Loss 3.6208 Acc 0.1720\n","Time taken for 1 epoch 5.44708251953125 sec\n","\n","Epoch 74 Loss 1.9961 Acc 0.3744\n","Validation Loss 3.6506 Acc 0.1703\n","Time taken for 1 epoch 5.395310163497925 sec\n","\n","Epoch 75 Loss 1.9948 Acc 0.3747\n","Validation Loss 3.6295 Acc 0.1715\n","Time taken for 1 epoch 5.473240852355957 sec\n","\n","Epoch 76 Loss 1.9975 Acc 0.3738\n","Validation Loss 3.6457 Acc 0.1687\n","Time taken for 1 epoch 5.483537435531616 sec\n","\n","Epoch 77 Loss 1.9938 Acc 0.3745\n","Validation Loss 3.6389 Acc 0.1719\n","Time taken for 1 epoch 5.439357757568359 sec\n","\n","Epoch 78 Loss 1.9893 Acc 0.3755\n","Validation Loss 3.6401 Acc 0.1705\n","Time taken for 1 epoch 5.470291614532471 sec\n","\n","Epoch 79 Loss 1.9943 Acc 0.3740\n","Validation Loss 3.6376 Acc 0.1719\n","Time taken for 1 epoch 5.4738147258758545 sec\n","\n","Epoch 80 Loss 1.9869 Acc 0.3762\n","Validation Loss 3.6475 Acc 0.1686\n","Time taken for 1 epoch 5.424915313720703 sec\n","\n","Epoch 81 Loss 1.9906 Acc 0.3750\n","Validation Loss 3.6302 Acc 0.1726\n","Time taken for 1 epoch 5.447588920593262 sec\n","\n","Epoch 82 Loss 1.9835 Acc 0.3768\n","Validation Loss 3.6528 Acc 0.1715\n","Time taken for 1 epoch 5.420946359634399 sec\n","\n","Epoch 83 Loss 1.9825 Acc 0.3771\n","Validation Loss 3.6365 Acc 0.1708\n","Time taken for 1 epoch 5.401310920715332 sec\n","\n","Epoch 84 Loss 1.9852 Acc 0.3762\n","Validation Loss 3.6508 Acc 0.1696\n","Time taken for 1 epoch 5.434292316436768 sec\n","\n","Epoch 85 Loss 1.9815 Acc 0.3771\n","Validation Loss 3.6418 Acc 0.1735\n","Time taken for 1 epoch 5.420320749282837 sec\n","\n","Epoch 86 Loss 1.9805 Acc 0.3772\n","Validation Loss 3.6628 Acc 0.1675\n","Time taken for 1 epoch 5.463986396789551 sec\n","\n","Epoch 87 Loss 1.9802 Acc 0.3772\n","Validation Loss 3.6330 Acc 0.1726\n","Time taken for 1 epoch 5.434303522109985 sec\n","\n","Epoch 88 Loss 1.9760 Acc 0.3783\n","Validation Loss 3.6560 Acc 0.1720\n","Time taken for 1 epoch 5.457859754562378 sec\n","\n","Epoch 89 Loss 1.9768 Acc 0.3779\n","Validation Loss 3.6520 Acc 0.1698\n","Time taken for 1 epoch 5.440417289733887 sec\n","\n","Epoch 90 Loss 1.9740 Acc 0.3785\n","Validation Loss 3.6277 Acc 0.1737\n","Time taken for 1 epoch 5.472720384597778 sec\n","\n","Epoch 91 Loss 1.9720 Acc 0.3791\n","Validation Loss 3.6630 Acc 0.1697\n","Time taken for 1 epoch 5.4216015338897705 sec\n","\n","Epoch 92 Loss 1.9734 Acc 0.3785\n","Validation Loss 3.6461 Acc 0.1720\n","Time taken for 1 epoch 5.450337648391724 sec\n","\n","Epoch 93 Loss 1.9703 Acc 0.3793\n","Validation Loss 3.6499 Acc 0.1707\n","Time taken for 1 epoch 5.427173376083374 sec\n","\n","Epoch 94 Loss 1.9701 Acc 0.3793\n","Validation Loss 3.6406 Acc 0.1734\n","Time taken for 1 epoch 5.402049779891968 sec\n","\n","Epoch 95 Loss 1.9670 Acc 0.3800\n","Validation Loss 3.6506 Acc 0.1700\n","Time taken for 1 epoch 5.448355197906494 sec\n","\n","Epoch 96 Loss 1.9691 Acc 0.3791\n","Validation Loss 3.6428 Acc 0.1719\n","Time taken for 1 epoch 5.4936041831970215 sec\n","\n","Epoch 97 Loss 1.9620 Acc 0.3812\n","Validation Loss 3.6503 Acc 0.1719\n","Time taken for 1 epoch 5.4661126136779785 sec\n","\n","Epoch 98 Loss 1.9604 Acc 0.3816\n","Validation Loss 3.6555 Acc 0.1710\n","Time taken for 1 epoch 5.427905797958374 sec\n","\n","Epoch 99 Loss 1.9703 Acc 0.3787\n","Validation Loss 3.6397 Acc 0.1709\n","Time taken for 1 epoch 5.439267873764038 sec\n","\n","Epoch 100 Loss 1.9608 Acc 0.3812\n","Validation Loss 3.6492 Acc 0.1713\n","Time taken for 1 epoch 5.48670220375061 sec\n","\n"]}],"source":["# set the epochs for training\n","EPOCHS = 100\n","\n","for epoch in range(EPOCHS):\n","    start = time.time()\n","\n","    # get the initial hidden state of gru\n","    total_loss = 0\n","    total_acc = 0\n","    steps_per_epoch = 0\n","    val_total_loss = 0\n","    val_total_acc = 0\n","    val_steps_per_epoch = 0\n","\n","    for x, y in easy_dataset:\n","        batch_loss, batch_acc = train_step(x, y)\n","        total_loss += batch_loss\n","        total_acc += batch_acc\n","        steps_per_epoch += 1\n","    \n","    for x, y in validation_dataset:\n","        val_batch_loss, val_batch_acc = val_step(x, y)\n","        val_total_loss += val_batch_loss\n","        val_total_acc += val_batch_acc\n","        val_steps_per_epoch += 1\n","    \n","    print(f'Epoch {epoch+1} Loss {total_loss / steps_per_epoch:.4f} Acc {total_acc / steps_per_epoch:.4f}')\n","    print(f'Validation Loss {val_total_loss / val_steps_per_epoch:.4f} Acc {val_total_acc / val_steps_per_epoch:.4f}')\n","    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n","    loss_history.append(float(total_loss / steps_per_epoch))\n","    acc_history.append(float(total_acc / steps_per_epoch))\n","    val_loss_history.append(float(val_total_loss / val_steps_per_epoch))\n","    val_acc_history.append(float(val_total_acc / val_steps_per_epoch))\n","\n","    # if (epoch+1) % 100 == 0:\n","    #     checkpoint.save(checkpoint_prefix)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":284},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1672388852215,"user":{"displayName":"邱奕傑","userId":"13446123829054950802"},"user_tz":-480},"id":"EFd-Y878I_ax","outputId":"15df5e3c-004d-4a8e-8aec-e215f7b16e83"},"outputs":[],"source":["# plt.plot(loss_history, label=\"train_loss\")\n","# plt.plot(val_loss_history, label=\"val_loss\")\n","# plt.xlabel(\"Epochs\")\n","# plt.ylabel(\"Loss\")\n","# plt.legend()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# plt.plot(acc_history, label=\"train_acc\")\n","# plt.plot(val_acc_history, label=\"val_acc\")\n","# plt.xlabel(\"Epochs\")\n","# plt.ylabel(\"Accuracy\")\n","# plt.legend()"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":602,"status":"ok","timestamp":1672388165994,"user":{"displayName":"邱奕傑","userId":"13446123829054950802"},"user_tz":-480},"id":"9dn_mVtnyx2t","outputId":"a2f4f1a8-9567-4a8b-c025-b023184bc569"},"outputs":[],"source":["checkpoint.save(checkpoint_prefix)\n","np.save(EXPERIMENT_DIR+\"stage1_loss_history.npy\", np.array(loss_history))\n","np.save(EXPERIMENT_DIR+\"stage1_acc_history.npy\", np.array(acc_history))\n","np.save(EXPERIMENT_DIR+\"stage1_val_loss_history.npy\", np.array(val_loss_history))\n","np.save(EXPERIMENT_DIR+\"stage1_val_acc_history.npy\", np.array(val_acc_history))"]},{"cell_type":"markdown","metadata":{},"source":["### stage 2"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["loss_history = []\n","val_loss_history = []\n","acc_history = []\n","val_acc_history = []"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1 Loss 2.2305 Acc 0.3432\n","Validation Loss 2.3461 Acc 0.3028\n","Time taken for 1 epoch 21.005409479141235 sec\n","\n","Epoch 2 Loss 2.2259 Acc 0.3451\n","Validation Loss 2.3698 Acc 0.2942\n","Time taken for 1 epoch 14.489409923553467 sec\n","\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[24], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m val_steps_per_epoch \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     15\u001b[0m \u001b[39mfor\u001b[39;00m x, y \u001b[39min\u001b[39;00m train_dataset:\n\u001b[0;32m---> 16\u001b[0m     batch_loss, batch_acc \u001b[39m=\u001b[39m train_step(x, y)\n\u001b[1;32m     17\u001b[0m     total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m batch_loss\n\u001b[1;32m     18\u001b[0m     total_acc \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m batch_acc\n","File \u001b[0;32m~/miniconda3/envs/p3-10/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n","File \u001b[0;32m~/miniconda3/envs/p3-10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    879\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 880\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    882\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    883\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n","File \u001b[0;32m~/miniconda3/envs/p3-10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:919\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    917\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    918\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 919\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    920\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[1;32m    921\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    922\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n","File \u001b[0;32m~/miniconda3/envs/p3-10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m   (concrete_function,\n\u001b[1;32m    133\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    135\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n","File \u001b[0;32m~/miniconda3/envs/p3-10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1741\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1742\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1743\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1744\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1745\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1746\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1747\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m     args,\n\u001b[1;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1750\u001b[0m     executing_eagerly)\n\u001b[1;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n","File \u001b[0;32m~/miniconda3/envs/p3-10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    377\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 378\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    379\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    380\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    381\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    382\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    383\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    384\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    386\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    387\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    391\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n","File \u001b[0;32m~/miniconda3/envs/p3-10/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# set the epochs for training\n","EPOCHS = 100\n","\n","for epoch in range(EPOCHS):\n","    start = time.time()\n","\n","    # get the initial hidden state of gru\n","    total_loss = 0\n","    total_acc = 0\n","    steps_per_epoch = 0\n","    val_total_loss = 0\n","    val_total_acc = 0\n","    val_steps_per_epoch = 0\n","\n","    for x, y in train_dataset:\n","        batch_loss, batch_acc = train_step(x, y)\n","        total_loss += batch_loss\n","        total_acc += batch_acc\n","        steps_per_epoch += 1\n","    \n","    for x, y in validation_dataset:\n","        val_batch_loss, val_batch_acc = val_step(x, y)\n","        val_total_loss += val_batch_loss\n","        val_total_acc += val_batch_acc\n","        val_steps_per_epoch += 1\n","    \n","    print(f'Epoch {epoch+1} Loss {total_loss / steps_per_epoch:.4f} Acc {total_acc / steps_per_epoch:.4f}')\n","    print(f'Validation Loss {val_total_loss / val_steps_per_epoch:.4f} Acc {val_total_acc / val_steps_per_epoch:.4f}')\n","    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n","    loss_history.append(float(total_loss / steps_per_epoch))\n","    acc_history.append(float(total_acc / steps_per_epoch))\n","    val_loss_history.append(float(val_total_loss / val_steps_per_epoch))\n","    val_acc_history.append(float(val_total_acc / val_steps_per_epoch))\n","\n","    # if (epoch+1) % 100 == 0:\n","    #     checkpoint.save(checkpoint_prefix)"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["checkpoint.save(checkpoint_prefix)\n","np.save(EXPERIMENT_DIR+\"stage2_loss_history.npy\", np.array(loss_history))\n","np.save(EXPERIMENT_DIR+\"stage2_acc_history.npy\", np.array(acc_history))\n","np.save(EXPERIMENT_DIR+\"stage2_val_loss_history.npy\", np.array(val_loss_history))\n","np.save(EXPERIMENT_DIR+\"stage2_val_acc_history.npy\", np.array(val_acc_history))"]},{"cell_type":"markdown","metadata":{"id":"2iKAgPMvkiXX"},"source":["## predict"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":325,"status":"ok","timestamp":1672401239979,"user":{"displayName":"邱奕傑","userId":"13446123829054950802"},"user_tz":-480},"id":"-MmaKSL2kiXY"},"outputs":[],"source":["def slice_per_step(a):\n","    # add -1 to the end of each sample to make them the same length per step(piece_length)\n","    original_length = a.shape[0]\n","    pad_count = PIECE_LEN - (original_length % PIECE_LEN)\n","    print(a.shape, end=' ')\n","    if pad_count!=PIECE_LEN : \n","        print('pad by',pad_count, end=' ')\n","        a = np.pad(a, ((0, pad_count), (0, 0)), 'constant', constant_values=-1)\n","    # reshape into per step\n","    a = np.reshape(a, (-1, PIECE_LEN, a.shape[1]))\n","    print('to',a.shape)\n","    return a, original_length"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":36,"status":"ok","timestamp":1672401237762,"user":{"displayName":"邱奕傑","userId":"13446123829054950802"},"user_tz":-480},"id":"gVm4TRw8Zc9I"},"outputs":[],"source":["import midi_np_translation.output2midi_v2_simple as output2midi"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["def test_and_translate_to_midi(input_path, ref_midi_path, output_path):\n","    test_file = np.load(input_path)\n","    padded_input, original_length = slice_per_step(test_file)\n","    test_result = np.reshape(model.predict(padded_input), (-1, 53))[:original_length]\n","    print(test_result.shape)\n","    output2midi.output_to_midi(test_result, ref_midi_path, output_path)"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(1560, 43) pad by 104 to (13, 128, 43)\n","1/1 [==============================] - 1s 1s/step\n","(1560, 53)\n","(1712, 43) pad by 80 to (14, 128, 43)\n","1/1 [==============================] - 0s 16ms/step\n","(1712, 53)\n","(3731, 43) pad by 109 to (30, 128, 43)\n","1/1 [==============================] - 0s 16ms/step\n","(3731, 53)\n","(3137, 43) pad by 63 to (25, 128, 43)\n","1/1 [==============================] - 0s 16ms/step\n","(3137, 53)\n","(1536, 43) to (12, 128, 43)\n","1/1 [==============================] - 0s 16ms/step\n","(1536, 53)\n"]}],"source":["test_and_translate_to_midi(input_path=\"preprocessed_dataset/irealpro_dataset_v2_simple/Autumn Leaves_o0.mid.npy\",\n","                           ref_midi_path=\"input_midi/irealpro_transposed/Autumn Leaves_o0.mid\",\n","                           output_path=EXPERIMENT_DIR+\"autumn_irealpro.mid\")\n","test_and_translate_to_midi(input_path=\"preprocessed_dataset/dense_v2_simple/AutumnLeaves_o0.mid.npy\",\n","                           ref_midi_path=\"input_midi/transpose_augmentation/AutumnLeaves_o0.mid\",\n","                           output_path=EXPERIMENT_DIR+\"autumn_arr.mid\")\n","test_and_translate_to_midi(input_path=\"preprocessed_dataset/midkar_v2_simple/autumn_leaves_pt_dm.mid.npy\",\n","                           ref_midi_path=\"input_midi/midkar/autumn_leaves_pt_dm.mid\",\n","                           output_path=EXPERIMENT_DIR+\"autumn_val.mid\")\n","test_and_translate_to_midi(input_path=\"preprocessed_dataset/midkar_v2_simple/the_song_is_you_mw.mid.npy\",\n","                           ref_midi_path=\"input_midi/midkar/the_song_is_you_mw.mid\",\n","                           output_path=EXPERIMENT_DIR+\"the_song_is_you.mid\")\n","test_and_translate_to_midi(input_path=\"preprocessed_dataset/midkar_v2_simple/a_night_in_tunisia_2_jc.mid.npy\",\n","                           ref_midi_path=\"input_midi/midkar/a_night_in_tunisia_2_jc.mid\",\n","                           output_path=EXPERIMENT_DIR+\"tunisia.mid\")"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.10.8 ('p3-10')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"30bf6d51b9778d445bda6ade898f7373f0f82efddc27825c86a16251dccb650c"}}},"nbformat":4,"nbformat_minor":0}
