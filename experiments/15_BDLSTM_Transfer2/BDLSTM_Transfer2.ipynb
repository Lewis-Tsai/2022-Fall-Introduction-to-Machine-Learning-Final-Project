{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":13294,"status":"ok","timestamp":1672401208022,"user":{"displayName":"邱奕傑","userId":"13446123829054950802"},"user_tz":-480},"id":"fTnVd_nOkiXG"},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-01-19 00:13:01.827987: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-01-19 00:13:02.401162: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n","2023-01-19 00:13:02.401244: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n","2023-01-19 00:13:02.401252: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"]}],"source":["import os\n","import time\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","\n","from tensorflow.keras.layers import Masking, Bidirectional, LSTM, TimeDistributed, Dense, Activation, BatchNormalization\n","from tensorflow.keras.regularizers import L2\n","\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":286,"status":"ok","timestamp":1672401210623,"user":{"displayName":"邱奕傑","userId":"13446123829054950802"},"user_tz":-480},"id":"nTjmuCsqkiXJ"},"outputs":[],"source":["EXPERIMENT_TITLE = \"15_BDLSTM_Transfer2/\"\n","EXPERIMENT_DIR = \"experiments/\" + EXPERIMENT_TITLE\n","\n","BATCH_SIZE = 4096\n","PIECE_LEN = 128\n","n_feature = 43\n","n_hidden = 100\n","n_pitch = 53\n","learning_rate = 0.001"]},{"cell_type":"markdown","metadata":{"id":"7z3W1cF8kiXK"},"source":["## build dataset"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":24,"status":"ok","timestamp":1672401213295,"user":{"displayName":"邱奕傑","userId":"13446123829054950802"},"user_tz":-480},"id":"Wzc45h8SkiXM"},"outputs":[],"source":["def load_npy_data(x_path, y_path, offset):\n","    x = np.load(x_path)\n","    y = np.load(y_path)\n","    if x.shape[0] >= offset+PIECE_LEN:\n","        return x[offset:offset+PIECE_LEN].astype(np.float64), y[offset:offset+PIECE_LEN].astype(np.float64)\n","    else:\n","        pad_count = offset + PIECE_LEN - x.shape[0]\n","        x = np.pad(x[offset:], ((0, pad_count), (0, 0)), 'constant', constant_values=-1).astype(np.float64)\n","        y = np.pad(y[offset:], ((0, pad_count), (0, 0)), 'constant', constant_values=-1).astype(np.float64)\n","        return x, y\n","\n","def generate_dataset(input_dir: str):\n","    x_paths = []\n","    y_paths = []\n","    offsets = []\n","    for file_name in sorted(os.listdir(input_dir)):\n","        if file_name.endswith(\".ans.npy\"):\n","            y_path = str(os.path.join(input_dir, file_name))\n","            x_path = str(os.path.join(input_dir, file_name.replace(\".ans.npy\", \".npy\")))\n","            assert os.path.exists(x_path), f\"corresponding input file {x_path} doesn't exist\"\n","            y_content = np.load(y_path)\n","            for offset in range(0, y_content.shape[0], PIECE_LEN):\n","                y_paths.append(y_path)\n","                x_paths.append(x_path)\n","                offsets.append(offset)\n","\n","    \n","    train_dataset = tf.data.Dataset.from_tensor_slices((x_paths, y_paths, offsets)).shuffle(100000)\n","    train_dataset = train_dataset.map(lambda x_path, y_path, offset: tf.numpy_function(load_npy_data, [x_path, y_path, offset], [tf.float64, tf.float64]))\n","    train_dataset = train_dataset.batch(BATCH_SIZE).prefetch(-1).cache()\n","    \n","    return train_dataset"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"afVoKJKK1QvD"},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-01-19 00:13:18.990350: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-19 00:13:18.994491: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-19 00:13:18.994654: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-19 00:13:18.994960: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-01-19 00:13:18.995571: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-19 00:13:18.995707: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-19 00:13:18.995815: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-19 00:13:19.418605: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-19 00:13:19.418786: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-19 00:13:19.418902: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-01-19 00:13:19.419042: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10397 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n"]},{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:From /media/labhdd/cyc/miniconda3/envs/p3-10/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n","Instructions for updating:\n","Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"]}],"source":["# easy_dataset = generate_dataset(\"./preprocessed_dataset/irealpro_dataset_v2_simple/\")\n","train_dataset = generate_dataset(\"preprocessed_dataset/augmentation_v2_simple\")\n","validation_dataset = generate_dataset(\"preprocessed_dataset/midkar_v2_simple\")"]},{"cell_type":"markdown","metadata":{"id":"EFZe6EfvkiXN"},"source":["## build model"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5723,"status":"ok","timestamp":1672401222694,"user":{"displayName":"邱奕傑","userId":"13446123829054950802"},"user_tz":-480},"id":"XLjpnzwTkiXO","outputId":"290c68af-8c74-43d7-83b4-bec22a85f6f4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 128, 43)]         0         \n","                                                                 \n"," mask (Masking)              (None, 128, 43)           0         \n","                                                                 \n"," input (TimeDistributed)     (None, 128, 100)          4400      \n","                                                                 \n"," bidirectional (Bidirectiona  (None, 128, 200)         160800    \n"," l)                                                              \n","                                                                 \n"," output (TimeDistributed)    (None, 128, 53)           10653     \n","                                                                 \n","=================================================================\n","Total params: 175,853\n","Trainable params: 175,853\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"]}],"source":["# print(\"Creating model\")\n","input = tf.keras.Input(shape=(PIECE_LEN, n_feature))  \n","x = Masking(mask_value=-1, input_shape=(PIECE_LEN, n_feature), name=\"mask\")(input) # Ignore Padded Data\n","x = TimeDistributed(Dense(n_hidden, activation=\"relu\", input_shape=(1, n_feature), kernel_regularizer=L2(0.001)), name=\"input\")(x)\n","x = Bidirectional(tf.keras.layers.LSTM(units=n_hidden, input_shape=(1, n_feature), return_sequences=True, kernel_regularizer=L2(0.0001), recurrent_regularizer=L2(0.0001)))(x)\n","x = TimeDistributed(Dense(n_pitch, activation=\"softmax\", kernel_regularizer=L2(0.001)), name=\"output\")(x)\n","model = tf.keras.Model(inputs=input, outputs=x)\n","print(model.summary())\n","optimizer=tf.keras.optimizers.experimental.Nadam(learning_rate=learning_rate)\n","# optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate)"]},{"cell_type":"markdown","metadata":{"id":"6MdoyCeYkiXQ"},"source":["## loss/accuracy function"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1672401222696,"user":{"displayName":"邱奕傑","userId":"13446123829054950802"},"user_tz":-480},"id":"x7-3osy8kiXR"},"outputs":[],"source":["@tf.function\n","def masked_loss_function(y_true, y_pred):\n","    mask = tf.math.not_equal(tf.reduce_sum(y_true, axis=2), -1*n_pitch)\n","    loss = tf.losses.categorical_crossentropy(y_true, y_pred)\n","    mask = tf.cast(mask, loss.dtype)\n","    loss *= mask\n","    return tf.reduce_mean(loss)\n","\n","@tf.function\n","def masked_accuracy(y_true, y_pred):\n","    mask = tf.math.not_equal(tf.reduce_sum(y_true, axis=2), -1*n_pitch)\n","    acc = tf.metrics.categorical_accuracy(y_true, y_pred)\n","    mask = tf.cast(mask, acc.dtype)\n","    acc *= mask\n","    return tf.reduce_mean(acc)"]},{"cell_type":"markdown","metadata":{"id":"f4ozM0e4DgdM"},"source":["### restore checkpoint"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"R7299W7uBURJ"},"outputs":[],"source":["checkpoint_dir = './checkpoints/' + EXPERIMENT_TITLE\n","checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n","checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n","                                 model=model)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":431,"status":"ok","timestamp":1672389872176,"user":{"displayName":"邱奕傑","userId":"13446123829054950802"},"user_tz":-480},"id":"8tzFhMQPBXY6","outputId":"67341b04-4dad-47da-9258-c558a187d0f3"},"outputs":[{"data":{"text/plain":["<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f1bafc4a410>"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["# checkpoint.restore(checkpoint_prefix+\"-1\")"]},{"cell_type":"markdown","metadata":{"id":"UmmelpaBkiXS"},"source":["## training"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":393,"status":"ok","timestamp":1672401230272,"user":{"displayName":"邱奕傑","userId":"13446123829054950802"},"user_tz":-480},"id":"rhWVti6IkiXU"},"outputs":[],"source":["@tf.function\n","def train_step(x, y):\n","    loss = 0\n","    with tf.GradientTape() as tape:\n","        pred = model(x)\n","        \n","        loss = masked_loss_function(y, pred)\n","        weight_decay = tf.reduce_sum(model.losses)\n","        loss += weight_decay\n","\n","    gradients = tape.gradient(loss, model.trainable_variables)\n","    gradients = [(tf.clip_by_value(grad, clip_value_min=-1.0, clip_value_max=1.0)) for grad in gradients]\n","\n","    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n","    acc = masked_accuracy(y, pred)\n","\n","    return loss, acc"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["@tf.function\n","def val_step(x, y):\n","    pred = model(x)\n","    loss = masked_loss_function(y, pred)\n","    weight_decay = tf.reduce_sum(model.losses)\n","    loss += weight_decay\n","    acc = masked_accuracy(y, pred)\n","    return loss, acc"]},{"cell_type":"markdown","metadata":{},"source":["### stage 1"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["loss_history = []\n","val_loss_history = []\n","acc_history = []\n","val_acc_history = []\n","# loss_history = np.load(EXPERIMENT_DIR+\"/loss_history.npy\")\n","# acc_history = np.load(EXPERIMENT_DIR+\"/acc_history.npy\")\n","# val_loss_history = np.load(EXPERIMENT_DIR+\"/val_loss_history.npy\")\n","# val_acc_history = np.load(EXPERIMENT_DIR+\"/val_acc_history.npy\")\n","# loss_history = np.load(\"experiments/BDLSTM_simple/history.npy\").tolist()"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":584744,"status":"error","timestamp":1672388158237,"user":{"displayName":"邱奕傑","userId":"13446123829054950802"},"user_tz":-480},"id":"MCXNL-sFkiXV","outputId":"5f268219-ecad-4ac1-c055-c41c218ec0e5"},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-01-18 23:34:44.779703: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n","type_id: TFT_OPTIONAL\n","args {\n","  type_id: TFT_PRODUCT\n","  args {\n","    type_id: TFT_TENSOR\n","    args {\n","      type_id: TFT_INT32\n","    }\n","  }\n","}\n"," is neither a subtype nor a supertype of the combined inputs preceding it:\n","type_id: TFT_OPTIONAL\n","args {\n","  type_id: TFT_PRODUCT\n","  args {\n","    type_id: TFT_TENSOR\n","    args {\n","      type_id: TFT_FLOAT\n","    }\n","  }\n","}\n","\n","\twhile inferring type of node 'cond_20/output/_23'\n","2023-01-18 23:34:45.841291: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8201\n","2023-01-18 23:34:46.846427: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7f34d0017270 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2023-01-18 23:34:46.846511: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1\n","2023-01-18 23:34:47.357029: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n","2023-01-18 23:34:49.131308: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:109] You are using ptxas 8.x, but TF requires ptxas 9.x (and strongly prefers >= 11.1).  Compilation of XLA kernels below will likely fail.\n","\n","You may not need to update CUDA; cherry-picking the ptxas binary is often sufficient.\n","2023-01-18 23:34:49.166993: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:234] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 6.1\n","2023-01-18 23:34:49.167030: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:237] Used ptxas at ptxas\n","2023-01-18 23:34:49.175012: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","2023-01-18 23:34:49.325722: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:109] You are using ptxas 8.x, but TF requires ptxas 9.x (and strongly prefers >= 11.1).  Compilation of XLA kernels below will likely fail.\n","\n","You may not need to update CUDA; cherry-picking the ptxas binary is often sufficient.\n","2023-01-18 23:34:49.434772: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:109] You are using ptxas 8.x, but TF requires ptxas 9.x (and strongly prefers >= 11.1).  Compilation of XLA kernels below will likely fail.\n","\n","You may not need to update CUDA; cherry-picking the ptxas binary is often sufficient.\n","2023-01-18 23:34:49.621175: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:109] You are using ptxas 8.x, but TF requires ptxas 9.x (and strongly prefers >= 11.1).  Compilation of XLA kernels below will likely fail.\n","\n","You may not need to update CUDA; cherry-picking the ptxas binary is often sufficient.\n","2023-01-18 23:34:49.738113: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:109] You are using ptxas 8.x, but TF requires ptxas 9.x (and strongly prefers >= 11.1).  Compilation of XLA kernels below will likely fail.\n","\n","You may not need to update CUDA; cherry-picking the ptxas binary is often sufficient.\n","2023-01-18 23:34:49.849973: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:109] You are using ptxas 8.x, but TF requires ptxas 9.x (and strongly prefers >= 11.1).  Compilation of XLA kernels below will likely fail.\n","\n","You may not need to update CUDA; cherry-picking the ptxas binary is often sufficient.\n","2023-01-18 23:34:50.008746: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:109] You are using ptxas 8.x, but TF requires ptxas 9.x (and strongly prefers >= 11.1).  Compilation of XLA kernels below will likely fail.\n","\n","You may not need to update CUDA; cherry-picking the ptxas binary is often sufficient.\n","2023-01-18 23:34:50.126590: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:109] You are using ptxas 8.x, but TF requires ptxas 9.x (and strongly prefers >= 11.1).  Compilation of XLA kernels below will likely fail.\n","\n","You may not need to update CUDA; cherry-picking the ptxas binary is often sufficient.\n","2023-01-18 23:34:50.235643: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:109] You are using ptxas 8.x, but TF requires ptxas 9.x (and strongly prefers >= 11.1).  Compilation of XLA kernels below will likely fail.\n","\n","You may not need to update CUDA; cherry-picking the ptxas binary is often sufficient.\n","2023-01-18 23:34:50.340594: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:109] You are using ptxas 8.x, but TF requires ptxas 9.x (and strongly prefers >= 11.1).  Compilation of XLA kernels below will likely fail.\n","\n","You may not need to update CUDA; cherry-picking the ptxas binary is often sufficient.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1 Loss 3.6489 Acc 0.0822\n","Validation Loss 3.5692 Acc 0.1055\n","Time taken for 1 epoch 80.34869360923767 sec\n","\n","Epoch 2 Loss 3.0148 Acc 0.1818\n","Validation Loss 3.5226 Acc 0.1528\n","Time taken for 1 epoch 5.332726716995239 sec\n","\n","Epoch 3 Loss 2.7952 Acc 0.2121\n","Validation Loss 3.5426 Acc 0.1632\n","Time taken for 1 epoch 5.367612361907959 sec\n","\n","Epoch 4 Loss 2.6813 Acc 0.2319\n","Validation Loss 3.5975 Acc 0.1643\n","Time taken for 1 epoch 5.3262622356414795 sec\n","\n","Epoch 5 Loss 2.6069 Acc 0.2461\n","Validation Loss 3.6115 Acc 0.1628\n","Time taken for 1 epoch 5.340776443481445 sec\n","\n","Epoch 6 Loss 2.5533 Acc 0.2568\n","Validation Loss 3.6049 Acc 0.1620\n","Time taken for 1 epoch 5.422240495681763 sec\n","\n","Epoch 7 Loss 2.5108 Acc 0.2652\n","Validation Loss 3.5968 Acc 0.1609\n","Time taken for 1 epoch 5.377564430236816 sec\n","\n","Epoch 8 Loss 2.4761 Acc 0.2722\n","Validation Loss 3.5932 Acc 0.1602\n","Time taken for 1 epoch 5.428133010864258 sec\n","\n","Epoch 9 Loss 2.4468 Acc 0.2780\n","Validation Loss 3.5861 Acc 0.1597\n","Time taken for 1 epoch 5.390653610229492 sec\n","\n","Epoch 10 Loss 2.4212 Acc 0.2831\n","Validation Loss 3.5838 Acc 0.1595\n","Time taken for 1 epoch 5.42213773727417 sec\n","\n","Epoch 11 Loss 2.3979 Acc 0.2880\n","Validation Loss 3.5769 Acc 0.1580\n","Time taken for 1 epoch 5.364761590957642 sec\n","\n","Epoch 12 Loss 2.3763 Acc 0.2928\n","Validation Loss 3.5766 Acc 0.1580\n","Time taken for 1 epoch 5.364170789718628 sec\n","\n","Epoch 13 Loss 2.3562 Acc 0.2972\n","Validation Loss 3.5836 Acc 0.1575\n","Time taken for 1 epoch 5.406705856323242 sec\n","\n","Epoch 14 Loss 2.3375 Acc 0.3014\n","Validation Loss 3.5760 Acc 0.1583\n","Time taken for 1 epoch 5.409255504608154 sec\n","\n","Epoch 15 Loss 2.3217 Acc 0.3046\n","Validation Loss 3.5788 Acc 0.1610\n","Time taken for 1 epoch 5.398235559463501 sec\n","\n","Epoch 16 Loss 2.3043 Acc 0.3086\n","Validation Loss 3.5668 Acc 0.1626\n","Time taken for 1 epoch 5.3992321491241455 sec\n","\n","Epoch 17 Loss 2.2881 Acc 0.3123\n","Validation Loss 3.5747 Acc 0.1633\n","Time taken for 1 epoch 5.40420937538147 sec\n","\n","Epoch 18 Loss 2.2753 Acc 0.3148\n","Validation Loss 3.5750 Acc 0.1629\n","Time taken for 1 epoch 5.442906141281128 sec\n","\n","Epoch 19 Loss 2.2586 Acc 0.3188\n","Validation Loss 3.5817 Acc 0.1589\n","Time taken for 1 epoch 5.3933117389678955 sec\n","\n","Epoch 20 Loss 2.2481 Acc 0.3209\n","Validation Loss 3.5717 Acc 0.1643\n","Time taken for 1 epoch 5.375800609588623 sec\n","\n","Epoch 21 Loss 2.2306 Acc 0.3251\n","Validation Loss 3.5774 Acc 0.1656\n","Time taken for 1 epoch 5.456169605255127 sec\n","\n","Epoch 22 Loss 2.2232 Acc 0.3261\n","Validation Loss 3.5983 Acc 0.1586\n","Time taken for 1 epoch 5.416736125946045 sec\n","\n","Epoch 23 Loss 2.2090 Acc 0.3298\n","Validation Loss 3.5739 Acc 0.1653\n","Time taken for 1 epoch 5.389141321182251 sec\n","\n","Epoch 24 Loss 2.1981 Acc 0.3322\n","Validation Loss 3.5918 Acc 0.1663\n","Time taken for 1 epoch 5.42405366897583 sec\n","\n","Epoch 25 Loss 2.1870 Acc 0.3347\n","Validation Loss 3.5835 Acc 0.1673\n","Time taken for 1 epoch 5.373851299285889 sec\n","\n","Epoch 26 Loss 2.1818 Acc 0.3355\n","Validation Loss 3.5932 Acc 0.1640\n","Time taken for 1 epoch 5.416126489639282 sec\n","\n","Epoch 27 Loss 2.1707 Acc 0.3382\n","Validation Loss 3.5863 Acc 0.1678\n","Time taken for 1 epoch 5.4186224937438965 sec\n","\n","Epoch 28 Loss 2.1623 Acc 0.3401\n","Validation Loss 3.5860 Acc 0.1689\n","Time taken for 1 epoch 5.453466176986694 sec\n","\n","Epoch 29 Loss 2.1523 Acc 0.3423\n","Validation Loss 3.6067 Acc 0.1640\n","Time taken for 1 epoch 5.408229351043701 sec\n","\n","Epoch 30 Loss 2.1525 Acc 0.3418\n","Validation Loss 3.5971 Acc 0.1675\n","Time taken for 1 epoch 5.414341688156128 sec\n","\n","Epoch 31 Loss 2.1386 Acc 0.3454\n","Validation Loss 3.5872 Acc 0.1672\n","Time taken for 1 epoch 5.416955471038818 sec\n","\n","Epoch 32 Loss 2.1354 Acc 0.3457\n","Validation Loss 3.6018 Acc 0.1694\n","Time taken for 1 epoch 5.454343795776367 sec\n","\n","Epoch 33 Loss 2.1251 Acc 0.3482\n","Validation Loss 3.6030 Acc 0.1646\n","Time taken for 1 epoch 5.421396970748901 sec\n","\n","Epoch 34 Loss 2.1247 Acc 0.3481\n","Validation Loss 3.5914 Acc 0.1682\n","Time taken for 1 epoch 5.432247877120972 sec\n","\n","Epoch 35 Loss 2.1129 Acc 0.3507\n","Validation Loss 3.6141 Acc 0.1681\n","Time taken for 1 epoch 5.401750564575195 sec\n","\n","Epoch 36 Loss 2.1124 Acc 0.3504\n","Validation Loss 3.5970 Acc 0.1700\n","Time taken for 1 epoch 5.394591569900513 sec\n","\n","Epoch 37 Loss 2.1027 Acc 0.3529\n","Validation Loss 3.6032 Acc 0.1664\n","Time taken for 1 epoch 5.4167258739471436 sec\n","\n","Epoch 38 Loss 2.1003 Acc 0.3532\n","Validation Loss 3.6121 Acc 0.1701\n","Time taken for 1 epoch 5.450695991516113 sec\n","\n","Epoch 39 Loss 2.0933 Acc 0.3547\n","Validation Loss 3.6160 Acc 0.1662\n","Time taken for 1 epoch 5.421535491943359 sec\n","\n","Epoch 40 Loss 2.0919 Acc 0.3547\n","Validation Loss 3.6068 Acc 0.1692\n","Time taken for 1 epoch 5.438124418258667 sec\n","\n","Epoch 41 Loss 2.0839 Acc 0.3568\n","Validation Loss 3.6169 Acc 0.1674\n","Time taken for 1 epoch 5.415390729904175 sec\n","\n","Epoch 42 Loss 2.0849 Acc 0.3561\n","Validation Loss 3.6074 Acc 0.1695\n","Time taken for 1 epoch 5.45453405380249 sec\n","\n","Epoch 43 Loss 2.0771 Acc 0.3580\n","Validation Loss 3.6350 Acc 0.1673\n","Time taken for 1 epoch 5.415782690048218 sec\n","\n","Epoch 44 Loss 2.0739 Acc 0.3586\n","Validation Loss 3.6129 Acc 0.1702\n","Time taken for 1 epoch 5.520174741744995 sec\n","\n","Epoch 45 Loss 2.0694 Acc 0.3595\n","Validation Loss 3.6155 Acc 0.1663\n","Time taken for 1 epoch 5.4304115772247314 sec\n","\n","Epoch 46 Loss 2.0664 Acc 0.3599\n","Validation Loss 3.6302 Acc 0.1698\n","Time taken for 1 epoch 5.403142929077148 sec\n","\n","Epoch 47 Loss 2.0612 Acc 0.3612\n","Validation Loss 3.6152 Acc 0.1686\n","Time taken for 1 epoch 5.444026470184326 sec\n","\n","Epoch 48 Loss 2.0650 Acc 0.3599\n","Validation Loss 3.6266 Acc 0.1679\n","Time taken for 1 epoch 5.444009304046631 sec\n","\n","Epoch 49 Loss 2.0547 Acc 0.3627\n","Validation Loss 3.6142 Acc 0.1707\n","Time taken for 1 epoch 5.397088289260864 sec\n","\n","Epoch 50 Loss 2.0519 Acc 0.3630\n","Validation Loss 3.6433 Acc 0.1673\n","Time taken for 1 epoch 5.417606592178345 sec\n","\n","Epoch 51 Loss 2.0523 Acc 0.3627\n","Validation Loss 3.6255 Acc 0.1709\n","Time taken for 1 epoch 5.674185037612915 sec\n","\n","Epoch 52 Loss 2.0445 Acc 0.3645\n","Validation Loss 3.6187 Acc 0.1698\n","Time taken for 1 epoch 5.426070690155029 sec\n","\n","Epoch 53 Loss 2.0446 Acc 0.3643\n","Validation Loss 3.6305 Acc 0.1702\n","Time taken for 1 epoch 5.422840356826782 sec\n","\n","Epoch 54 Loss 2.0389 Acc 0.3656\n","Validation Loss 3.6363 Acc 0.1686\n","Time taken for 1 epoch 5.457747220993042 sec\n","\n","Epoch 55 Loss 2.0404 Acc 0.3652\n","Validation Loss 3.6145 Acc 0.1702\n","Time taken for 1 epoch 5.473368406295776 sec\n","\n","Epoch 56 Loss 2.0367 Acc 0.3659\n","Validation Loss 3.6421 Acc 0.1685\n","Time taken for 1 epoch 5.38884425163269 sec\n","\n","Epoch 57 Loss 2.0360 Acc 0.3660\n","Validation Loss 3.6273 Acc 0.1719\n","Time taken for 1 epoch 5.436188459396362 sec\n","\n","Epoch 58 Loss 2.0296 Acc 0.3674\n","Validation Loss 3.6518 Acc 0.1671\n","Time taken for 1 epoch 5.432775497436523 sec\n","\n","Epoch 59 Loss 2.0303 Acc 0.3671\n","Validation Loss 3.6167 Acc 0.1711\n","Time taken for 1 epoch 5.462135553359985 sec\n","\n","Epoch 60 Loss 2.0241 Acc 0.3686\n","Validation Loss 3.6392 Acc 0.1689\n","Time taken for 1 epoch 5.450441122055054 sec\n","\n","Epoch 61 Loss 2.0256 Acc 0.3680\n","Validation Loss 3.6360 Acc 0.1720\n","Time taken for 1 epoch 5.43477725982666 sec\n","\n","Epoch 62 Loss 2.0197 Acc 0.3695\n","Validation Loss 3.6417 Acc 0.1680\n","Time taken for 1 epoch 5.450706720352173 sec\n","\n","Epoch 63 Loss 2.0203 Acc 0.3692\n","Validation Loss 3.6193 Acc 0.1725\n","Time taken for 1 epoch 5.452277183532715 sec\n","\n","Epoch 64 Loss 2.0181 Acc 0.3696\n","Validation Loss 3.6441 Acc 0.1689\n","Time taken for 1 epoch 5.487454891204834 sec\n","\n","Epoch 65 Loss 2.0140 Acc 0.3706\n","Validation Loss 3.6286 Acc 0.1722\n","Time taken for 1 epoch 5.408638954162598 sec\n","\n","Epoch 66 Loss 2.0132 Acc 0.3705\n","Validation Loss 3.6326 Acc 0.1680\n","Time taken for 1 epoch 5.423679351806641 sec\n","\n","Epoch 67 Loss 2.0126 Acc 0.3706\n","Validation Loss 3.6338 Acc 0.1710\n","Time taken for 1 epoch 5.444218873977661 sec\n","\n","Epoch 68 Loss 2.0086 Acc 0.3715\n","Validation Loss 3.6525 Acc 0.1702\n","Time taken for 1 epoch 5.49013090133667 sec\n","\n","Epoch 69 Loss 2.0087 Acc 0.3716\n","Validation Loss 3.6242 Acc 0.1709\n","Time taken for 1 epoch 5.426387071609497 sec\n","\n","Epoch 70 Loss 2.0039 Acc 0.3729\n","Validation Loss 3.6506 Acc 0.1683\n","Time taken for 1 epoch 5.436451196670532 sec\n","\n","Epoch 71 Loss 2.0058 Acc 0.3722\n","Validation Loss 3.6386 Acc 0.1732\n","Time taken for 1 epoch 5.39172101020813 sec\n","\n","Epoch 72 Loss 2.0012 Acc 0.3733\n","Validation Loss 3.6517 Acc 0.1667\n","Time taken for 1 epoch 5.39306378364563 sec\n","\n","Epoch 73 Loss 2.0019 Acc 0.3728\n","Validation Loss 3.6208 Acc 0.1720\n","Time taken for 1 epoch 5.44708251953125 sec\n","\n","Epoch 74 Loss 1.9961 Acc 0.3744\n","Validation Loss 3.6506 Acc 0.1703\n","Time taken for 1 epoch 5.395310163497925 sec\n","\n","Epoch 75 Loss 1.9948 Acc 0.3747\n","Validation Loss 3.6295 Acc 0.1715\n","Time taken for 1 epoch 5.473240852355957 sec\n","\n","Epoch 76 Loss 1.9975 Acc 0.3738\n","Validation Loss 3.6457 Acc 0.1687\n","Time taken for 1 epoch 5.483537435531616 sec\n","\n","Epoch 77 Loss 1.9938 Acc 0.3745\n","Validation Loss 3.6389 Acc 0.1719\n","Time taken for 1 epoch 5.439357757568359 sec\n","\n","Epoch 78 Loss 1.9893 Acc 0.3755\n","Validation Loss 3.6401 Acc 0.1705\n","Time taken for 1 epoch 5.470291614532471 sec\n","\n","Epoch 79 Loss 1.9943 Acc 0.3740\n","Validation Loss 3.6376 Acc 0.1719\n","Time taken for 1 epoch 5.4738147258758545 sec\n","\n","Epoch 80 Loss 1.9869 Acc 0.3762\n","Validation Loss 3.6475 Acc 0.1686\n","Time taken for 1 epoch 5.424915313720703 sec\n","\n","Epoch 81 Loss 1.9906 Acc 0.3750\n","Validation Loss 3.6302 Acc 0.1726\n","Time taken for 1 epoch 5.447588920593262 sec\n","\n","Epoch 82 Loss 1.9835 Acc 0.3768\n","Validation Loss 3.6528 Acc 0.1715\n","Time taken for 1 epoch 5.420946359634399 sec\n","\n","Epoch 83 Loss 1.9825 Acc 0.3771\n","Validation Loss 3.6365 Acc 0.1708\n","Time taken for 1 epoch 5.401310920715332 sec\n","\n","Epoch 84 Loss 1.9852 Acc 0.3762\n","Validation Loss 3.6508 Acc 0.1696\n","Time taken for 1 epoch 5.434292316436768 sec\n","\n","Epoch 85 Loss 1.9815 Acc 0.3771\n","Validation Loss 3.6418 Acc 0.1735\n","Time taken for 1 epoch 5.420320749282837 sec\n","\n","Epoch 86 Loss 1.9805 Acc 0.3772\n","Validation Loss 3.6628 Acc 0.1675\n","Time taken for 1 epoch 5.463986396789551 sec\n","\n","Epoch 87 Loss 1.9802 Acc 0.3772\n","Validation Loss 3.6330 Acc 0.1726\n","Time taken for 1 epoch 5.434303522109985 sec\n","\n","Epoch 88 Loss 1.9760 Acc 0.3783\n","Validation Loss 3.6560 Acc 0.1720\n","Time taken for 1 epoch 5.457859754562378 sec\n","\n","Epoch 89 Loss 1.9768 Acc 0.3779\n","Validation Loss 3.6520 Acc 0.1698\n","Time taken for 1 epoch 5.440417289733887 sec\n","\n","Epoch 90 Loss 1.9740 Acc 0.3785\n","Validation Loss 3.6277 Acc 0.1737\n","Time taken for 1 epoch 5.472720384597778 sec\n","\n","Epoch 91 Loss 1.9720 Acc 0.3791\n","Validation Loss 3.6630 Acc 0.1697\n","Time taken for 1 epoch 5.4216015338897705 sec\n","\n","Epoch 92 Loss 1.9734 Acc 0.3785\n","Validation Loss 3.6461 Acc 0.1720\n","Time taken for 1 epoch 5.450337648391724 sec\n","\n","Epoch 93 Loss 1.9703 Acc 0.3793\n","Validation Loss 3.6499 Acc 0.1707\n","Time taken for 1 epoch 5.427173376083374 sec\n","\n","Epoch 94 Loss 1.9701 Acc 0.3793\n","Validation Loss 3.6406 Acc 0.1734\n","Time taken for 1 epoch 5.402049779891968 sec\n","\n","Epoch 95 Loss 1.9670 Acc 0.3800\n","Validation Loss 3.6506 Acc 0.1700\n","Time taken for 1 epoch 5.448355197906494 sec\n","\n","Epoch 96 Loss 1.9691 Acc 0.3791\n","Validation Loss 3.6428 Acc 0.1719\n","Time taken for 1 epoch 5.4936041831970215 sec\n","\n","Epoch 97 Loss 1.9620 Acc 0.3812\n","Validation Loss 3.6503 Acc 0.1719\n","Time taken for 1 epoch 5.4661126136779785 sec\n","\n","Epoch 98 Loss 1.9604 Acc 0.3816\n","Validation Loss 3.6555 Acc 0.1710\n","Time taken for 1 epoch 5.427905797958374 sec\n","\n","Epoch 99 Loss 1.9703 Acc 0.3787\n","Validation Loss 3.6397 Acc 0.1709\n","Time taken for 1 epoch 5.439267873764038 sec\n","\n","Epoch 100 Loss 1.9608 Acc 0.3812\n","Validation Loss 3.6492 Acc 0.1713\n","Time taken for 1 epoch 5.48670220375061 sec\n","\n"]}],"source":["# set the epochs for training\n","EPOCHS = 100\n","\n","for epoch in range(EPOCHS):\n","    start = time.time()\n","\n","    # get the initial hidden state of gru\n","    total_loss = 0\n","    total_acc = 0\n","    steps_per_epoch = 0\n","    val_total_loss = 0\n","    val_total_acc = 0\n","    val_steps_per_epoch = 0\n","\n","    for x, y in easy_dataset:\n","        batch_loss, batch_acc = train_step(x, y)\n","        total_loss += batch_loss\n","        total_acc += batch_acc\n","        steps_per_epoch += 1\n","    \n","    for x, y in validation_dataset:\n","        val_batch_loss, val_batch_acc = val_step(x, y)\n","        val_total_loss += val_batch_loss\n","        val_total_acc += val_batch_acc\n","        val_steps_per_epoch += 1\n","    \n","    print(f'Epoch {epoch+1} Loss {total_loss / steps_per_epoch:.4f} Acc {total_acc / steps_per_epoch:.4f}')\n","    print(f'Validation Loss {val_total_loss / val_steps_per_epoch:.4f} Acc {val_total_acc / val_steps_per_epoch:.4f}')\n","    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n","    loss_history.append(float(total_loss / steps_per_epoch))\n","    acc_history.append(float(total_acc / steps_per_epoch))\n","    val_loss_history.append(float(val_total_loss / val_steps_per_epoch))\n","    val_acc_history.append(float(val_total_acc / val_steps_per_epoch))\n","\n","    # if (epoch+1) % 100 == 0:\n","    #     checkpoint.save(checkpoint_prefix)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":284},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1672388852215,"user":{"displayName":"邱奕傑","userId":"13446123829054950802"},"user_tz":-480},"id":"EFd-Y878I_ax","outputId":"15df5e3c-004d-4a8e-8aec-e215f7b16e83"},"outputs":[],"source":["# plt.plot(loss_history, label=\"train_loss\")\n","# plt.plot(val_loss_history, label=\"val_loss\")\n","# plt.xlabel(\"Epochs\")\n","# plt.ylabel(\"Loss\")\n","# plt.legend()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# plt.plot(acc_history, label=\"train_acc\")\n","# plt.plot(val_acc_history, label=\"val_acc\")\n","# plt.xlabel(\"Epochs\")\n","# plt.ylabel(\"Accuracy\")\n","# plt.legend()"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":602,"status":"ok","timestamp":1672388165994,"user":{"displayName":"邱奕傑","userId":"13446123829054950802"},"user_tz":-480},"id":"9dn_mVtnyx2t","outputId":"a2f4f1a8-9567-4a8b-c025-b023184bc569"},"outputs":[],"source":["checkpoint.save(checkpoint_prefix)\n","np.save(EXPERIMENT_DIR+\"stage1_loss_history.npy\", np.array(loss_history))\n","np.save(EXPERIMENT_DIR+\"stage1_acc_history.npy\", np.array(acc_history))\n","np.save(EXPERIMENT_DIR+\"stage1_val_loss_history.npy\", np.array(val_loss_history))\n","np.save(EXPERIMENT_DIR+\"stage1_val_acc_history.npy\", np.array(val_acc_history))"]},{"cell_type":"markdown","metadata":{},"source":["### stage 2"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["loss_history = []\n","val_loss_history = []\n","acc_history = []\n","val_acc_history = []"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-01-19 00:14:02.326925: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n","type_id: TFT_OPTIONAL\n","args {\n","  type_id: TFT_PRODUCT\n","  args {\n","    type_id: TFT_TENSOR\n","    args {\n","      type_id: TFT_INT32\n","    }\n","  }\n","}\n"," is neither a subtype nor a supertype of the combined inputs preceding it:\n","type_id: TFT_OPTIONAL\n","args {\n","  type_id: TFT_PRODUCT\n","  args {\n","    type_id: TFT_TENSOR\n","    args {\n","      type_id: TFT_FLOAT\n","    }\n","  }\n","}\n","\n","\twhile inferring type of node 'cond_20/output/_23'\n","2023-01-19 00:14:02.719674: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8201\n","2023-01-19 00:14:03.425752: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7f1af0002890 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2023-01-19 00:14:03.425780: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1\n","2023-01-19 00:14:03.434497: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n","2023-01-19 00:14:03.537804: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:109] You are using ptxas 8.x, but TF requires ptxas 9.x (and strongly prefers >= 11.1).  Compilation of XLA kernels below will likely fail.\n","\n","You may not need to update CUDA; cherry-picking the ptxas binary is often sufficient.\n","2023-01-19 00:14:03.567926: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:234] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 6.1\n","2023-01-19 00:14:03.567964: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:237] Used ptxas at ptxas\n","2023-01-19 00:14:03.569113: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","2023-01-19 00:14:03.644166: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:109] You are using ptxas 8.x, but TF requires ptxas 9.x (and strongly prefers >= 11.1).  Compilation of XLA kernels below will likely fail.\n","\n","You may not need to update CUDA; cherry-picking the ptxas binary is often sufficient.\n","2023-01-19 00:14:03.753833: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:109] You are using ptxas 8.x, but TF requires ptxas 9.x (and strongly prefers >= 11.1).  Compilation of XLA kernels below will likely fail.\n","\n","You may not need to update CUDA; cherry-picking the ptxas binary is often sufficient.\n","2023-01-19 00:14:03.857089: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:109] You are using ptxas 8.x, but TF requires ptxas 9.x (and strongly prefers >= 11.1).  Compilation of XLA kernels below will likely fail.\n","\n","You may not need to update CUDA; cherry-picking the ptxas binary is often sufficient.\n","2023-01-19 00:14:03.968502: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:109] You are using ptxas 8.x, but TF requires ptxas 9.x (and strongly prefers >= 11.1).  Compilation of XLA kernels below will likely fail.\n","\n","You may not need to update CUDA; cherry-picking the ptxas binary is often sufficient.\n","2023-01-19 00:14:04.076720: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:109] You are using ptxas 8.x, but TF requires ptxas 9.x (and strongly prefers >= 11.1).  Compilation of XLA kernels below will likely fail.\n","\n","You may not need to update CUDA; cherry-picking the ptxas binary is often sufficient.\n","2023-01-19 00:14:04.182988: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:109] You are using ptxas 8.x, but TF requires ptxas 9.x (and strongly prefers >= 11.1).  Compilation of XLA kernels below will likely fail.\n","\n","You may not need to update CUDA; cherry-picking the ptxas binary is often sufficient.\n","2023-01-19 00:14:04.291804: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:109] You are using ptxas 8.x, but TF requires ptxas 9.x (and strongly prefers >= 11.1).  Compilation of XLA kernels below will likely fail.\n","\n","You may not need to update CUDA; cherry-picking the ptxas binary is often sufficient.\n","2023-01-19 00:14:04.396830: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:109] You are using ptxas 8.x, but TF requires ptxas 9.x (and strongly prefers >= 11.1).  Compilation of XLA kernels below will likely fail.\n","\n","You may not need to update CUDA; cherry-picking the ptxas binary is often sufficient.\n","2023-01-19 00:14:04.504070: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:109] You are using ptxas 8.x, but TF requires ptxas 9.x (and strongly prefers >= 11.1).  Compilation of XLA kernels below will likely fail.\n","\n","You may not need to update CUDA; cherry-picking the ptxas binary is often sufficient.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1 Loss 2.6840 Acc 0.2525\n","Validation Loss 2.5980 Acc 0.2549\n","Time taken for 1 epoch 306.3796513080597 sec\n","\n","Epoch 2 Loss 2.5256 Acc 0.2738\n","Validation Loss 2.5592 Acc 0.2609\n","Time taken for 1 epoch 14.863803386688232 sec\n","\n","Epoch 3 Loss 2.4937 Acc 0.2787\n","Validation Loss 2.5385 Acc 0.2626\n","Time taken for 1 epoch 15.007849216461182 sec\n","\n","Epoch 4 Loss 2.4738 Acc 0.2815\n","Validation Loss 2.5176 Acc 0.2641\n","Time taken for 1 epoch 14.937923669815063 sec\n","\n","Epoch 5 Loss 2.4603 Acc 0.2833\n","Validation Loss 2.5012 Acc 0.2680\n","Time taken for 1 epoch 15.027761697769165 sec\n","\n","Epoch 6 Loss 2.4477 Acc 0.2852\n","Validation Loss 2.4926 Acc 0.2684\n","Time taken for 1 epoch 15.038921356201172 sec\n","\n","Epoch 7 Loss 2.4378 Acc 0.2867\n","Validation Loss 2.4817 Acc 0.2697\n","Time taken for 1 epoch 15.015776634216309 sec\n","\n","Epoch 8 Loss 2.4315 Acc 0.2876\n","Validation Loss 2.4842 Acc 0.2688\n","Time taken for 1 epoch 15.21206521987915 sec\n","\n","Epoch 9 Loss 2.4233 Acc 0.2886\n","Validation Loss 2.4721 Acc 0.2709\n","Time taken for 1 epoch 15.044737815856934 sec\n","\n","Epoch 10 Loss 2.4137 Acc 0.2906\n","Validation Loss 2.4727 Acc 0.2692\n","Time taken for 1 epoch 15.059624433517456 sec\n","\n","Epoch 11 Loss 2.4086 Acc 0.2919\n","Validation Loss 2.4488 Acc 0.2767\n","Time taken for 1 epoch 14.979638576507568 sec\n","\n","Epoch 12 Loss 2.4004 Acc 0.2934\n","Validation Loss 2.5244 Acc 0.2506\n","Time taken for 1 epoch 15.071324825286865 sec\n","\n","Epoch 13 Loss 2.4005 Acc 0.2933\n","Validation Loss 2.4379 Acc 0.2796\n","Time taken for 1 epoch 15.09896206855774 sec\n","\n","Epoch 14 Loss 2.3918 Acc 0.2949\n","Validation Loss 2.4770 Acc 0.2656\n","Time taken for 1 epoch 15.166505813598633 sec\n","\n","Epoch 15 Loss 2.3843 Acc 0.2977\n","Validation Loss 2.4343 Acc 0.2767\n","Time taken for 1 epoch 15.202752351760864 sec\n","\n","Epoch 16 Loss 2.3808 Acc 0.2982\n","Validation Loss 2.4192 Acc 0.2834\n","Time taken for 1 epoch 15.25727391242981 sec\n","\n","Epoch 17 Loss 2.3809 Acc 0.2980\n","Validation Loss 2.4221 Acc 0.2834\n","Time taken for 1 epoch 15.18197751045227 sec\n","\n","Epoch 18 Loss 2.3700 Acc 0.3013\n","Validation Loss 2.4119 Acc 0.2846\n","Time taken for 1 epoch 15.172706365585327 sec\n","\n","Epoch 19 Loss 2.3662 Acc 0.3019\n","Validation Loss 2.4209 Acc 0.2829\n","Time taken for 1 epoch 15.239529609680176 sec\n","\n","Epoch 20 Loss 2.3605 Acc 0.3033\n","Validation Loss 2.4102 Acc 0.2867\n","Time taken for 1 epoch 15.134736776351929 sec\n","\n","Epoch 21 Loss 2.3613 Acc 0.3035\n","Validation Loss 2.4060 Acc 0.2887\n","Time taken for 1 epoch 15.238469123840332 sec\n","\n","Epoch 22 Loss 2.3623 Acc 0.3041\n","Validation Loss 2.3989 Acc 0.2872\n","Time taken for 1 epoch 15.318245887756348 sec\n","\n","Epoch 23 Loss 2.3487 Acc 0.3069\n","Validation Loss 2.3895 Acc 0.2926\n","Time taken for 1 epoch 15.228250980377197 sec\n","\n","Epoch 24 Loss 2.3435 Acc 0.3085\n","Validation Loss 2.3880 Acc 0.2916\n","Time taken for 1 epoch 15.22040581703186 sec\n","\n","Epoch 25 Loss 2.3479 Acc 0.3080\n","Validation Loss 2.3944 Acc 0.2920\n","Time taken for 1 epoch 15.026215314865112 sec\n","\n","Epoch 26 Loss 2.3431 Acc 0.3086\n","Validation Loss 2.3952 Acc 0.2913\n","Time taken for 1 epoch 15.181659936904907 sec\n","\n","Epoch 27 Loss 2.3374 Acc 0.3104\n","Validation Loss 2.3870 Acc 0.2947\n","Time taken for 1 epoch 15.213340520858765 sec\n","\n","Epoch 28 Loss 2.3244 Acc 0.3146\n","Validation Loss 2.3797 Acc 0.2912\n","Time taken for 1 epoch 15.163729429244995 sec\n","\n","Epoch 29 Loss 2.3239 Acc 0.3141\n","Validation Loss 2.3708 Acc 0.2972\n","Time taken for 1 epoch 15.229040384292603 sec\n","\n","Epoch 30 Loss 2.3155 Acc 0.3174\n","Validation Loss 2.3668 Acc 0.2969\n","Time taken for 1 epoch 15.233922243118286 sec\n","\n","Epoch 31 Loss 2.3220 Acc 0.3146\n","Validation Loss 2.3767 Acc 0.2960\n","Time taken for 1 epoch 15.087727308273315 sec\n","\n","Epoch 32 Loss 2.3083 Acc 0.3194\n","Validation Loss 2.4084 Acc 0.2867\n","Time taken for 1 epoch 15.179012060165405 sec\n","\n","Epoch 33 Loss 2.3076 Acc 0.3194\n","Validation Loss 2.3692 Acc 0.2996\n","Time taken for 1 epoch 15.023369073867798 sec\n","\n","Epoch 34 Loss 2.3086 Acc 0.3186\n","Validation Loss 2.3973 Acc 0.2894\n","Time taken for 1 epoch 15.208622932434082 sec\n","\n","Epoch 35 Loss 2.3084 Acc 0.3192\n","Validation Loss 2.3636 Acc 0.2993\n","Time taken for 1 epoch 15.197914838790894 sec\n","\n","Epoch 36 Loss 2.2917 Acc 0.3245\n","Validation Loss 2.4045 Acc 0.2884\n","Time taken for 1 epoch 15.180685758590698 sec\n","\n","Epoch 37 Loss 2.2878 Acc 0.3256\n","Validation Loss 2.3724 Acc 0.2975\n","Time taken for 1 epoch 15.32290530204773 sec\n","\n","Epoch 38 Loss 2.2826 Acc 0.3272\n","Validation Loss 2.3476 Acc 0.3032\n","Time taken for 1 epoch 14.995038032531738 sec\n","\n","Epoch 39 Loss 2.2754 Acc 0.3297\n","Validation Loss 2.3480 Acc 0.3017\n","Time taken for 1 epoch 15.188626050949097 sec\n","\n","Epoch 40 Loss 2.2764 Acc 0.3289\n","Validation Loss 2.3722 Acc 0.2969\n","Time taken for 1 epoch 15.174773216247559 sec\n","\n","Epoch 41 Loss 2.2731 Acc 0.3298\n","Validation Loss 2.3497 Acc 0.3031\n","Time taken for 1 epoch 15.12190866470337 sec\n","\n","Epoch 42 Loss 2.2652 Acc 0.3326\n","Validation Loss 2.3395 Acc 0.3050\n","Time taken for 1 epoch 15.20074200630188 sec\n","\n","Epoch 43 Loss 2.2676 Acc 0.3313\n","Validation Loss 2.3524 Acc 0.3028\n","Time taken for 1 epoch 15.267535924911499 sec\n","\n","Epoch 44 Loss 2.2603 Acc 0.3340\n","Validation Loss 2.3407 Acc 0.3045\n","Time taken for 1 epoch 15.015450477600098 sec\n","\n","Epoch 45 Loss 2.2686 Acc 0.3310\n","Validation Loss 2.3353 Acc 0.3054\n","Time taken for 1 epoch 15.218104839324951 sec\n","\n","Epoch 46 Loss 2.2564 Acc 0.3348\n","Validation Loss 2.3316 Acc 0.3074\n","Time taken for 1 epoch 15.254090070724487 sec\n","\n","Epoch 47 Loss 2.2628 Acc 0.3324\n","Validation Loss 2.3372 Acc 0.3060\n","Time taken for 1 epoch 15.146036148071289 sec\n","\n","Epoch 48 Loss 2.2511 Acc 0.3365\n","Validation Loss 2.3287 Acc 0.3082\n","Time taken for 1 epoch 15.256044864654541 sec\n","\n","Epoch 49 Loss 2.2556 Acc 0.3345\n","Validation Loss 2.3313 Acc 0.3062\n","Time taken for 1 epoch 15.197016477584839 sec\n","\n","Epoch 50 Loss 2.2988 Acc 0.3213\n","Validation Loss 2.4169 Acc 0.2855\n","Time taken for 1 epoch 15.037944316864014 sec\n","\n","Epoch 51 Loss 2.3260 Acc 0.3155\n","Validation Loss 2.4125 Acc 0.2882\n","Time taken for 1 epoch 15.118051767349243 sec\n","\n","Epoch 52 Loss 2.2955 Acc 0.3239\n","Validation Loss 2.3523 Acc 0.3028\n","Time taken for 1 epoch 15.036715984344482 sec\n","\n","Epoch 53 Loss 2.2782 Acc 0.3286\n","Validation Loss 2.3711 Acc 0.2978\n","Time taken for 1 epoch 15.053906202316284 sec\n","\n","Epoch 54 Loss 2.2621 Acc 0.3335\n","Validation Loss 2.3962 Acc 0.2900\n","Time taken for 1 epoch 15.145939826965332 sec\n","\n","Epoch 55 Loss 2.2596 Acc 0.3338\n","Validation Loss 2.3381 Acc 0.3054\n","Time taken for 1 epoch 15.064866304397583 sec\n","\n","Epoch 56 Loss 2.2559 Acc 0.3347\n","Validation Loss 2.3539 Acc 0.3031\n","Time taken for 1 epoch 15.012229204177856 sec\n","\n","Epoch 57 Loss 2.2474 Acc 0.3375\n","Validation Loss 2.3586 Acc 0.3009\n","Time taken for 1 epoch 15.102724075317383 sec\n","\n","Epoch 58 Loss 2.2594 Acc 0.3333\n","Validation Loss 2.3376 Acc 0.3073\n","Time taken for 1 epoch 15.200932502746582 sec\n","\n","Epoch 59 Loss 2.2471 Acc 0.3369\n","Validation Loss 2.3358 Acc 0.3075\n","Time taken for 1 epoch 15.166090250015259 sec\n","\n","Epoch 60 Loss 2.2604 Acc 0.3332\n","Validation Loss 2.3610 Acc 0.3003\n","Time taken for 1 epoch 15.178315162658691 sec\n","\n","Epoch 61 Loss 2.2607 Acc 0.3328\n","Validation Loss 2.3695 Acc 0.2979\n","Time taken for 1 epoch 15.187447547912598 sec\n","\n","Epoch 62 Loss 2.2436 Acc 0.3380\n","Validation Loss 2.3586 Acc 0.2971\n","Time taken for 1 epoch 15.242742538452148 sec\n","\n","Epoch 63 Loss 2.2427 Acc 0.3379\n","Validation Loss 2.3304 Acc 0.3094\n","Time taken for 1 epoch 15.167259216308594 sec\n","\n","Epoch 64 Loss 2.2342 Acc 0.3408\n","Validation Loss 2.3977 Acc 0.2899\n","Time taken for 1 epoch 15.305201053619385 sec\n","\n","Epoch 65 Loss 2.2375 Acc 0.3396\n","Validation Loss 2.3266 Acc 0.3073\n","Time taken for 1 epoch 15.351447820663452 sec\n","\n","Epoch 66 Loss 2.2327 Acc 0.3409\n","Validation Loss 2.3211 Acc 0.3111\n","Time taken for 1 epoch 15.05850601196289 sec\n","\n","Epoch 67 Loss 2.2301 Acc 0.3419\n","Validation Loss 2.3516 Acc 0.2983\n","Time taken for 1 epoch 15.138893365859985 sec\n","\n","Epoch 68 Loss 2.2280 Acc 0.3422\n","Validation Loss 2.3232 Acc 0.3088\n","Time taken for 1 epoch 15.193595170974731 sec\n","\n","Epoch 69 Loss 2.2263 Acc 0.3427\n","Validation Loss 2.3169 Acc 0.3114\n","Time taken for 1 epoch 15.272698402404785 sec\n","\n","Epoch 70 Loss 2.2232 Acc 0.3434\n","Validation Loss 2.3251 Acc 0.3073\n","Time taken for 1 epoch 15.164087295532227 sec\n","\n","Epoch 71 Loss 2.2457 Acc 0.3366\n","Validation Loss 2.3755 Acc 0.2951\n","Time taken for 1 epoch 15.219617366790771 sec\n","\n","Epoch 72 Loss 2.2438 Acc 0.3370\n","Validation Loss 2.3283 Acc 0.3071\n","Time taken for 1 epoch 15.239861011505127 sec\n","\n","Epoch 73 Loss 2.2233 Acc 0.3432\n","Validation Loss 2.3238 Acc 0.3076\n","Time taken for 1 epoch 15.033033609390259 sec\n","\n","Epoch 74 Loss 2.2207 Acc 0.3442\n","Validation Loss 2.3201 Acc 0.3092\n","Time taken for 1 epoch 15.253423690795898 sec\n","\n","Epoch 75 Loss 2.2187 Acc 0.3448\n","Validation Loss 2.3142 Acc 0.3113\n","Time taken for 1 epoch 15.225458860397339 sec\n","\n","Epoch 76 Loss 2.2191 Acc 0.3446\n","Validation Loss 2.3192 Acc 0.3099\n","Time taken for 1 epoch 15.298303365707397 sec\n","\n","Epoch 77 Loss 2.2178 Acc 0.3447\n","Validation Loss 2.3668 Acc 0.2975\n","Time taken for 1 epoch 15.280996084213257 sec\n","\n","Epoch 78 Loss 2.2172 Acc 0.3451\n","Validation Loss 2.3332 Acc 0.3044\n","Time taken for 1 epoch 15.221513271331787 sec\n","\n","Epoch 79 Loss 2.2158 Acc 0.3452\n","Validation Loss 2.3333 Acc 0.3065\n","Time taken for 1 epoch 15.252272844314575 sec\n","\n","Epoch 80 Loss 2.2139 Acc 0.3460\n","Validation Loss 2.3522 Acc 0.3005\n","Time taken for 1 epoch 15.25099229812622 sec\n","\n","Epoch 81 Loss 2.2116 Acc 0.3463\n","Validation Loss 2.3382 Acc 0.3057\n","Time taken for 1 epoch 15.092222213745117 sec\n","\n","Epoch 82 Loss 2.2156 Acc 0.3456\n","Validation Loss 2.3324 Acc 0.3037\n","Time taken for 1 epoch 15.09255075454712 sec\n","\n","Epoch 83 Loss 2.2109 Acc 0.3466\n","Validation Loss 2.3135 Acc 0.3111\n","Time taken for 1 epoch 15.225086450576782 sec\n","\n","Epoch 84 Loss 2.2303 Acc 0.3405\n","Validation Loss 2.3658 Acc 0.2965\n","Time taken for 1 epoch 15.190751075744629 sec\n","\n","Epoch 85 Loss 2.2231 Acc 0.3426\n","Validation Loss 2.3294 Acc 0.3044\n","Time taken for 1 epoch 15.235562324523926 sec\n","\n","Epoch 86 Loss 2.2113 Acc 0.3459\n","Validation Loss 2.3521 Acc 0.3017\n","Time taken for 1 epoch 15.28026270866394 sec\n","\n","Epoch 87 Loss 2.2098 Acc 0.3471\n","Validation Loss 2.3417 Acc 0.3007\n","Time taken for 1 epoch 15.087970733642578 sec\n","\n","Epoch 88 Loss 2.2059 Acc 0.3480\n","Validation Loss 2.3189 Acc 0.3078\n","Time taken for 1 epoch 15.040817260742188 sec\n","\n","Epoch 89 Loss 2.2069 Acc 0.3475\n","Validation Loss 2.3449 Acc 0.3007\n","Time taken for 1 epoch 15.16135287284851 sec\n","\n","Epoch 90 Loss 2.2079 Acc 0.3470\n","Validation Loss 2.3583 Acc 0.2995\n","Time taken for 1 epoch 15.031095743179321 sec\n","\n","Epoch 91 Loss 2.2071 Acc 0.3475\n","Validation Loss 2.3209 Acc 0.3108\n","Time taken for 1 epoch 15.073345184326172 sec\n","\n","Epoch 92 Loss 2.2019 Acc 0.3494\n","Validation Loss 2.3183 Acc 0.3070\n","Time taken for 1 epoch 15.190551042556763 sec\n","\n","Epoch 93 Loss 2.2134 Acc 0.3453\n","Validation Loss 2.3378 Acc 0.3035\n","Time taken for 1 epoch 15.247031927108765 sec\n","\n","Epoch 94 Loss 2.2057 Acc 0.3476\n","Validation Loss 2.3122 Acc 0.3121\n","Time taken for 1 epoch 15.050183534622192 sec\n","\n","Epoch 95 Loss 2.1965 Acc 0.3511\n","Validation Loss 2.3224 Acc 0.3056\n","Time taken for 1 epoch 15.126834630966187 sec\n","\n","Epoch 96 Loss 2.2023 Acc 0.3483\n","Validation Loss 2.3687 Acc 0.2961\n","Time taken for 1 epoch 15.254135847091675 sec\n","\n","Epoch 97 Loss 2.2029 Acc 0.3487\n","Validation Loss 2.3265 Acc 0.3063\n","Time taken for 1 epoch 15.042958736419678 sec\n","\n","Epoch 98 Loss 2.1961 Acc 0.3507\n","Validation Loss 2.3428 Acc 0.3045\n","Time taken for 1 epoch 15.148590803146362 sec\n","\n","Epoch 99 Loss 2.2053 Acc 0.3476\n","Validation Loss 2.3155 Acc 0.3127\n","Time taken for 1 epoch 15.153528928756714 sec\n","\n","Epoch 100 Loss 2.2071 Acc 0.3473\n","Validation Loss 2.3771 Acc 0.2941\n","Time taken for 1 epoch 14.972477912902832 sec\n","\n"]}],"source":["# set the epochs for training\n","EPOCHS = 100\n","\n","for epoch in range(EPOCHS):\n","    start = time.time()\n","\n","    # get the initial hidden state of gru\n","    total_loss = 0\n","    total_acc = 0\n","    steps_per_epoch = 0\n","    val_total_loss = 0\n","    val_total_acc = 0\n","    val_steps_per_epoch = 0\n","\n","    for x, y in train_dataset:\n","        batch_loss, batch_acc = train_step(x, y)\n","        total_loss += batch_loss\n","        total_acc += batch_acc\n","        steps_per_epoch += 1\n","    \n","    for x, y in validation_dataset:\n","        val_batch_loss, val_batch_acc = val_step(x, y)\n","        val_total_loss += val_batch_loss\n","        val_total_acc += val_batch_acc\n","        val_steps_per_epoch += 1\n","    \n","    print(f'Epoch {epoch+1} Loss {total_loss / steps_per_epoch:.4f} Acc {total_acc / steps_per_epoch:.4f}')\n","    print(f'Validation Loss {val_total_loss / val_steps_per_epoch:.4f} Acc {val_total_acc / val_steps_per_epoch:.4f}')\n","    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n","    loss_history.append(float(total_loss / steps_per_epoch))\n","    acc_history.append(float(total_acc / steps_per_epoch))\n","    val_loss_history.append(float(val_total_loss / val_steps_per_epoch))\n","    val_acc_history.append(float(val_total_acc / val_steps_per_epoch))\n","\n","    # if (epoch+1) % 100 == 0:\n","    #     checkpoint.save(checkpoint_prefix)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["checkpoint.save(checkpoint_prefix)\n","np.save(EXPERIMENT_DIR+\"stage2_loss_history.npy\", np.array(loss_history))\n","np.save(EXPERIMENT_DIR+\"stage2_acc_history.npy\", np.array(acc_history))\n","np.save(EXPERIMENT_DIR+\"stage2_val_loss_history.npy\", np.array(val_loss_history))\n","np.save(EXPERIMENT_DIR+\"stage2_val_acc_history.npy\", np.array(val_acc_history))"]},{"cell_type":"markdown","metadata":{"id":"2iKAgPMvkiXX"},"source":["## predict"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":325,"status":"ok","timestamp":1672401239979,"user":{"displayName":"邱奕傑","userId":"13446123829054950802"},"user_tz":-480},"id":"-MmaKSL2kiXY"},"outputs":[],"source":["def slice_per_step(a):\n","    # add -1 to the end of each sample to make them the same length per step(piece_length)\n","    original_length = a.shape[0]\n","    pad_count = PIECE_LEN - (original_length % PIECE_LEN)\n","    print(a.shape, end=' ')\n","    if pad_count!=PIECE_LEN : \n","        print('pad by',pad_count, end=' ')\n","        a = np.pad(a, ((0, pad_count), (0, 0)), 'constant', constant_values=-1)\n","    # reshape into per step\n","    a = np.reshape(a, (-1, PIECE_LEN, a.shape[1]))\n","    print('to',a.shape)\n","    return a, original_length"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":36,"status":"ok","timestamp":1672401237762,"user":{"displayName":"邱奕傑","userId":"13446123829054950802"},"user_tz":-480},"id":"gVm4TRw8Zc9I"},"outputs":[],"source":["import midi_np_translation.output2midi_v2_simple as output2midi"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["def test_and_translate_to_midi(input_path, ref_midi_path, output_path):\n","    test_file = np.load(input_path)\n","    padded_input, original_length = slice_per_step(test_file)\n","    test_result = np.reshape(model.predict(padded_input), (-1, 53))[:original_length]\n","    print(test_result.shape)\n","    output2midi.output_to_midi(test_result, ref_midi_path, output_path)"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(1560, 43) pad by 104 to (13, 128, 43)\n","1/1 [==============================] - 2s 2s/step\n","(1560, 53)\n","(1712, 43) pad by 80 to (14, 128, 43)\n","1/1 [==============================] - 0s 16ms/step\n","(1712, 53)\n","(3731, 43) pad by 109 to (30, 128, 43)\n","1/1 [==============================] - 0s 16ms/step\n","(3731, 53)\n","(3137, 43) pad by 63 to (25, 128, 43)\n","1/1 [==============================] - 0s 16ms/step\n","(3137, 53)\n","(1536, 43) to (12, 128, 43)\n","1/1 [==============================] - 0s 16ms/step\n","(1536, 53)\n"]}],"source":["test_and_translate_to_midi(input_path=\"preprocessed_dataset/irealpro_dataset_v2_simple/Autumn Leaves_o0.mid.npy\",\n","                           ref_midi_path=\"input_midi/irealpro_transposed/Autumn Leaves_o0.mid\",\n","                           output_path=EXPERIMENT_DIR+\"autumn_irealpro.mid\")\n","test_and_translate_to_midi(input_path=\"preprocessed_dataset/dense_v2_simple/AutumnLeaves_o0.mid.npy\",\n","                           ref_midi_path=\"input_midi/transpose_augmentation/AutumnLeaves_o0.mid\",\n","                           output_path=EXPERIMENT_DIR+\"autumn_arr.mid\")\n","test_and_translate_to_midi(input_path=\"preprocessed_dataset/midkar_v2_simple/autumn_leaves_pt_dm.mid.npy\",\n","                           ref_midi_path=\"input_midi/midkar/autumn_leaves_pt_dm.mid\",\n","                           output_path=EXPERIMENT_DIR+\"autumn_val.mid\")\n","test_and_translate_to_midi(input_path=\"preprocessed_dataset/midkar_v2_simple/the_song_is_you_mw.mid.npy\",\n","                           ref_midi_path=\"input_midi/midkar/the_song_is_you_mw.mid\",\n","                           output_path=EXPERIMENT_DIR+\"the_song_is_you.mid\")\n","test_and_translate_to_midi(input_path=\"preprocessed_dataset/midkar_v2_simple/a_night_in_tunisia_2_jc.mid.npy\",\n","                           ref_midi_path=\"input_midi/midkar/a_night_in_tunisia_2_jc.mid\",\n","                           output_path=EXPERIMENT_DIR+\"tunisia.mid\")"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.10.8 ('p3-10')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"30bf6d51b9778d445bda6ade898f7373f0f82efddc27825c86a16251dccb650c"}}},"nbformat":4,"nbformat_minor":0}
