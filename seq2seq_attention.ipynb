{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drcZacjAs_GF",
        "outputId": "b4ff5640-c841-47ad-9583-1d6be78e67b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow-gpu in /usr/local/lib/python3.8/dist-packages (2.11.0)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (2.11.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (3.19.6)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (1.3.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (23.1.4)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (1.6.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (2.2.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (0.29.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (1.21.6)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (1.51.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (1.14.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (3.3.0)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (2.11.2)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (15.0.6.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (2.11.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (0.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (57.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (4.4.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow-gpu) (0.38.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu) (2.25.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu) (2.16.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu) (3.4.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow-gpu) (3.0.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-gpu) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-gpu) (5.2.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-gpu) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-gpu) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow-gpu) (6.0.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-gpu) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-gpu) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-gpu) (2022.12.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow-gpu) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-gpu) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-gpu) (3.2.2)\n",
            "2.11.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow_addons in /usr/local/lib/python3.8/dist-packages (0.19.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow_addons) (21.3)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow_addons) (2.7.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow_addons) (3.0.9)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (4.64.1)\n"
          ]
        }
      ],
      "source": [
        "! pip3 install tensorflow-gpu\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "! pip3 install tensorflow_addons\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "! pip3 install tqdm\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kzNGWq3zuPs"
      },
      "source": [
        "# **Parameter**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMWZqy8YmmEs",
        "outputId": "fac779d0-108d-45d7-e3af-b494f0936811"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "WTcqMEfUCkm_"
      },
      "outputs": [],
      "source": [
        "# Original Data Info.\n",
        "n_pitch = 53\n",
        "n_feature = 43\n",
        "\n",
        "# Model Parameter\n",
        "input_size = n_feature\n",
        "target_size = n_pitch + 4 # (+4 addition) are oneset + start correction + end correction + velocity\n",
        "\n",
        "# Training Parameter\n",
        "BATCH_SIZE = 32          # Batch Sizes\n",
        "VALIDATION_RATIO = 0.1  # Validation Ratio to Input Data\n",
        "learning_rate = 0.001   # Learning Rate\n",
        "n_hidden = 100            # Hidden Units number\n",
        "\n",
        "# Data Parameter\n",
        "PIECE_LEN = 200          # (auto set by data) Extra +1 for START timestamp\n",
        "is_onset_index = 53\n",
        "start_correction_index = 54\n",
        "end_correction_index = 55\n",
        "velocity_index = 56\n",
        "key_order = ['pitch', 'onset', 'start', 'end', 'velocity']\n",
        "\n",
        "ROOT = r'/content/drive/MyDrive/ML'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8iDHeXjo2Zc",
        "outputId": "f2037682-df99-46a7-9a38-7c8a9c4bd7f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ML\n"
          ]
        }
      ],
      "source": [
        "os.chdir(ROOT)\n",
        "print(os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "jcLw90VlRmfe"
      },
      "outputs": [],
      "source": [
        "from zipfile import ZipFile\n",
        "# Delete incomplete unzipped folder and run this \n",
        "if 'irealpro_dataset_v2' not in os.listdir():\n",
        "    print('Creating Folder \\'irealpro_dataset_v2\\'')\n",
        "    os.mkdir('../irealpro_dataset_v2')\n",
        "    print('Extract to Folder \\'irealpro_dataset_v2\\'')\n",
        "    with ZipFile(r\"/content/drive/MyDrive/ML/irealpro_dataset_v2.zip\", 'r') as zObject:\n",
        "        zObject.extractall(path=r\"/content/drive/MyDrive/ML/irealpro_dataset_v2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "ZmoVUOkVMRUc"
      },
      "outputs": [],
      "source": [
        "np.random.seed(10000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJU0zll_pAsL"
      },
      "source": [
        "# **Data Preparation**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`MAX_DATA`: control how many songs files as the input (assign with -1 to use all songs)"
      ],
      "metadata": {
        "id": "m1xHWMb-HTZ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_DATA = 10"
      ],
      "metadata": {
        "id": "p_vke-NwHoP0"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3Tj17ylBnes",
        "outputId": "78374afc-f91d-4e0d-e9c9-48308e3c0e70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "86\n",
            "(1, 86, 200, 43)\n",
            "(1, 86, 1, 57)\n",
            "(1, 86, 200, 57)\n",
            "Data Padded: 9\n",
            "Data with Non Start Decoder Input: 77\n",
            "Data PIECE_LEN: 200\n"
          ]
        }
      ],
      "source": [
        "dec_init_input = np.zeros((1, target_size))\n",
        "dec_init_input[0, start_correction_index] = 1.\n",
        "\n",
        "count_pad = 0 \n",
        "count_spilled = 0\n",
        "def load_npy_data(x_path, y_path, offset):\n",
        "    global count_pad, count_spilled, dec_init_input\n",
        "    x = np.load(x_path)\n",
        "    y = np.load(y_path)\n",
        "\n",
        "    if offset == 0:\n",
        "        Z_ = dec_init_input\n",
        "    else:\n",
        "        Z_ = y[offset-1].astype(np.float32)\n",
        "        Z_ = np.expand_dims(Z_, axis=0)\n",
        "        count_spilled += 1\n",
        "\n",
        "    if x.shape[0] >= offset+PIECE_LEN:\n",
        "        X_ = x[offset:offset+PIECE_LEN].astype(np.float32)\n",
        "        Y_ = y[offset:offset+PIECE_LEN].astype(np.float32)\n",
        "    else:\n",
        "        pad_count = offset + PIECE_LEN - x.shape[0]\n",
        "        X_ = np.pad(x[offset:], ((0, pad_count), (0, 0)), 'constant', constant_values=-1).astype(np.float32)\n",
        "        Y_ = np.pad(y[offset:], ((0, pad_count), (0, 0)), 'constant', constant_values=-1).astype(np.float32)\n",
        "        count_pad += 1\n",
        "    try:\n",
        "        assert X_.shape == (PIECE_LEN, input_size)\n",
        "        assert Z_.shape == (1, target_size)\n",
        "        assert Y_.shape == (PIECE_LEN, target_size)\n",
        "    except:\n",
        "        print('You got',X_.shape, Z_.shape, Y_.shape)\n",
        "        raise ValueError\n",
        "\n",
        "    return X_, Z_, Y_\n",
        "\n",
        "def generate_dataset(input_dir: str, data_size=-1):\n",
        "    # using tf.data.Dataset API to create dataset\n",
        "    x_paths = [] # input path\n",
        "    y_paths = [] # ans file path\n",
        "    offsets = [] # starting point of a piece\n",
        "    data_cnt = 0\n",
        "    for file_name in os.listdir(input_dir): # 'Scan Files'\n",
        "        if data_cnt==data_size-1: break\n",
        "        if file_name.endswith(\".ans.npy\"):\n",
        "            data_cnt+=1\n",
        "            y_path = str(os.path.join(input_dir, file_name))\n",
        "            x_path = str(os.path.join(input_dir, file_name[:-8] + \".npy\"))\n",
        "            assert os.path.exists(x_path), f\"corresponding input file {x_path} doesn't exist\"\n",
        "\n",
        "            # split and pad data into PIECE_LEN\n",
        "            y_content = np.load(y_path)\n",
        "            for offset in range(0, y_content.shape[0], PIECE_LEN):\n",
        "                y_paths.append(y_path)\n",
        "                x_paths.append(x_path)\n",
        "                offsets.append(offset)\n",
        "\n",
        "    dataset = []\n",
        "    for i in zip(x_paths, y_paths, offsets): # 'Read Files'\n",
        "        dataset.append(load_npy_data(*i))\n",
        "    print(len(dataset))\n",
        "    dataset = list(zip(*dataset))\n",
        "    # print(len(dataset[0]))\n",
        "    # print(len(dataset[1]))\n",
        "    # print(len(dataset[2]))\n",
        "    encoder_input_data = np.array(dataset[0])\n",
        "    decoder_input_data = np.array(dataset[1])\n",
        "    decoder_target_data = np.array(dataset[2])\n",
        "    \n",
        "    perm_id = np.random.shuffle(np.arange(encoder_input_data.shape[0]))\n",
        "    encoder_input_data = encoder_input_data[perm_id]\n",
        "    decoder_input_data = decoder_input_data[perm_id]\n",
        "    decoder_target_data = decoder_target_data[perm_id]\n",
        "    \n",
        "    print(encoder_input_data.shape)\n",
        "    print(decoder_input_data.shape)\n",
        "    print(decoder_target_data.shape)\n",
        "\n",
        "    pitch_target, onset_target, start_target, end_target, velocity_target = np.split(decoder_target_data, [n_pitch+i for i in range(4)], axis=-1)\n",
        "    decoder_target_data = (pitch_target, onset_target, start_target, end_target, velocity_target)\n",
        "\n",
        "    return encoder_input_data, decoder_input_data, decoder_target_data\n",
        "\n",
        "encoder_input_data, decoder_input_data, decoder_target_data = generate_dataset(ROOT+\"/irealpro_dataset_v2\", MAX_DATA)\n",
        "\n",
        "print('Data Padded:', count_pad)\n",
        "print('Data with Non Start Decoder Input:', count_spilled)\n",
        "print('Data PIECE_LEN:', PIECE_LEN)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if encoder_input_data.shape[0] == 1:\n",
        "    print(\"Remove Unwanted Dimension and Split Labels\")\n",
        "    print(encoder_input_data.shape)\n",
        "    print(decoder_input_data.shape)\n",
        "    for target in decoder_target_data:\n",
        "        print(target.shape)\n",
        "    encoder_input_data = tf.reshape(encoder_input_data, encoder_input_data.shape[1:])\n",
        "    decoder_input_data = tf.reshape(decoder_input_data, decoder_input_data.shape[1:])\n",
        "    decoder_target_data = [tf.reshape(target, target.shape[1:]) for target in decoder_target_data]\n",
        "    decoder_target_data = {key: decoder_target_data[i] for i, key in enumerate(key_order)} # Split target data to each key_order (labels)\n",
        "    print(encoder_input_data.shape)\n",
        "    print(decoder_input_data.shape)\n",
        "    for key in decoder_target_data:\n",
        "        print(decoder_target_data[key].shape)\n",
        "\n",
        "inputs = tf.data.Dataset.zip(tuple([tf.data.Dataset.from_tensor_slices((encoder_input_data)), tf.data.Dataset.from_tensor_slices((decoder_input_data))]))\n",
        "outputs = tf.data.Dataset.from_tensor_slices((decoder_target_data))\n",
        "\n",
        "train_dataset = tf.data.Dataset.zip((inputs, outputs))\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UL_RAqgzr-Zk",
        "outputId": "3dca5f7d-1585-4839-a709-204f09614e96"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Remove Unwanted Dimension and Split Labels\n",
            "(1, 86, 200, 43)\n",
            "(1, 86, 1, 57)\n",
            "(1, 86, 200, 53)\n",
            "(1, 86, 200, 1)\n",
            "(1, 86, 200, 1)\n",
            "(1, 86, 200, 1)\n",
            "(1, 86, 200, 1)\n",
            "(86, 200, 43)\n",
            "(86, 1, 57)\n",
            "(86, 200, 53)\n",
            "(86, 200, 1)\n",
            "(86, 200, 1)\n",
            "(86, 200, 1)\n",
            "(86, 200, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs.element_spec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFMn1WSQsVxt",
        "outputId": "bf0bffdd-c60b-4a69-ca54-e393ffa71b57"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorSpec(shape=(200, 43), dtype=tf.float32, name=None),\n",
              " TensorSpec(shape=(1, 57), dtype=tf.float64, name=None))"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs.element_spec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qH8foyJosXJ9",
        "outputId": "8d0bce39-7628-4d5c-d1a4-3bfd3fcc303c"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'pitch': TensorSpec(shape=(200, 53), dtype=tf.float32, name=None),\n",
              " 'onset': TensorSpec(shape=(200, 1), dtype=tf.float32, name=None),\n",
              " 'start': TensorSpec(shape=(200, 1), dtype=tf.float32, name=None),\n",
              " 'end': TensorSpec(shape=(200, 1), dtype=tf.float32, name=None),\n",
              " 'velocity': TensorSpec(shape=(200, 1), dtype=tf.float32, name=None)}"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysk_4cPxhPJw"
      },
      "source": [
        "# **Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EN1ooFJHhGvt"
      },
      "source": [
        "## *Define Loss, Accuracy, and Optimizer*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "Jqzuy9Z9rTRj"
      },
      "outputs": [],
      "source": [
        "# Define Loss, Accuracy, and Optimizer\n",
        "def masked_loss_function(y_true: tf.Tensor, y_pred: tf.Tensor):\n",
        "    mask = tf.math.not_equal(tf.reduce_sum(y_true[:,:,:n_pitch], axis=2), -1*n_pitch)  # false if it is a padding time step\n",
        "    pitch_loss = tf.losses.categorical_crossentropy(y_true[:,:,:n_pitch], y_pred[:,:,:n_pitch])\n",
        "    onset_loss = tf.losses.binary_crossentropy(y_true[:,:,n_pitch:n_pitch+1], y_pred[:,:,n_pitch:n_pitch+1])\n",
        "    start_loss = tf.square(y_true[:,:,n_pitch+1] - y_pred[:,:,n_pitch+1])\n",
        "    end_loss = tf.square(y_true[:,:,n_pitch+2] - y_pred[:,:,n_pitch+2])\n",
        "    velocity_loss = tf.square(y_true[:,:,n_pitch+3] - y_pred[:,:,n_pitch+3])\n",
        "    total_loss = tf.reduce_sum([pitch_loss, onset_loss, start_loss, end_loss, velocity_loss], axis=0)\n",
        "    total_loss *= tf.cast(mask, total_loss.dtype)\n",
        "    return tf.reduce_mean(total_loss)\n",
        "\n",
        "def mse_with_positive_pressure(y_true: tf.Tensor, y_pred: tf.Tensor):\n",
        "    mse = (y_true - y_pred) ** 2\n",
        "    positive_pressure = 10 * tf.maximum(-y_pred, 0.0)\n",
        "    return tf.reduce_mean(mse + positive_pressure)\n",
        "\n",
        "def pitch_loss(y_true: tf.Tensor, y_pred: tf.Tensor):\n",
        "    mask = tf.math.not_equal(tf.reduce_sum(y_true, axis=2), -1*n_pitch)  # false if it is a padding time step\n",
        "    pitch_l = tf.losses.categorical_crossentropy(y_true, y_pred)\n",
        "    return pitch_l * tf.cast(mask, pitch_l.dtype) \n",
        "def onset_loss(y_true: tf.Tensor, y_pred: tf.Tensor):\n",
        "    mask = tf.math.not_equal(tf.reduce_sum(y_true, axis=2), -1*n_pitch)  # false if it is a padding time step\n",
        "    onset_l = tf.losses.binary_crossentropy(y_true, y_pred)\n",
        "    return onset_l * tf.cast(mask, onset_l.dtype) \n",
        "def start_loss(y_true: tf.Tensor, y_pred: tf.Tensor):\n",
        "    mask = tf.math.not_equal(tf.reduce_sum(y_true, axis=2), -1*n_pitch)  # false if it is a padding time step\n",
        "    start_l = tf.square(y_true - y_pred)\n",
        "    return start_l * tf.cast(mask, start_l.dtype) \n",
        "def end_loss(y_true: tf.Tensor, y_pred: tf.Tensor):\n",
        "    mask = tf.math.not_equal(tf.reduce_sum(y_true, axis=2), -1*n_pitch)  # false if it is a padding time step\n",
        "    end_l = tf.square(y_true - y_pred)\n",
        "    return end_l * tf.cast(mask, end_l.dtype) \n",
        "def velocity_loss(y_true: tf.Tensor, y_pred: tf.Tensor):\n",
        "    mask = tf.math.not_equal(tf.reduce_sum(y_true, axis=2), -1*n_pitch)  # false if it is a padding time step\n",
        "    velocity_l = tf.square(y_true - y_pred)\n",
        "    return velocity_l * tf.cast(mask, velocity_l.dtype) \n",
        "\n",
        "def pitch_accuracy(y_true: tf.Tensor, y_pred: tf.Tensor):\n",
        "    mask = tf.math.not_equal(tf.reduce_sum(y_true, axis=2), -1*n_pitch)  # false if it is a padding time step\n",
        "    mask = tf.cast(mask, tf.float32)\n",
        "    pitch_acc = tf.reduce_mean(mask * tf.metrics.categorical_accuracy(y_true, y_pred))\n",
        "    return pitch_acc\n",
        "def onset_accuracy(y_true: tf.Tensor, y_pred: tf.Tensor):\n",
        "    mask = tf.math.not_equal(tf.reduce_sum(y_true, axis=2), -1*n_pitch)  # false if it is a padding time step\n",
        "    mask = tf.cast(mask, tf.float32)\n",
        "    onset_acc = tf.reduce_mean(mask * tf.metrics.binary_accuracy(y_true, y_pred))\n",
        "    return onset_acc\n",
        "def start_accuracy(y_true: tf.Tensor, y_pred: tf.Tensor):\n",
        "    mask = tf.math.not_equal(tf.reduce_sum(y_true, axis=2), -1*n_pitch)  # false if it is a padding time step\n",
        "    mask = tf.cast(mask, tf.float32)\n",
        "    start_acc = tf.reduce_mean(mask * tf.square(y_true - y_pred))\n",
        "    return start_acc\n",
        "def end_accuracy(y_true: tf.Tensor, y_pred: tf.Tensor):\n",
        "    mask = tf.math.not_equal(tf.reduce_sum(y_true, axis=2), -1*n_pitch)  # false if it is a padding time step\n",
        "    mask = tf.cast(mask, tf.float32)\n",
        "    end_acc = tf.reduce_mean(mask * tf.square(y_true - y_pred))\n",
        "    return end_acc\n",
        "def velocity_accuracy(y_true: tf.Tensor, y_pred: tf.Tensor):\n",
        "    mask = tf.math.not_equal(tf.reduce_sum(y_true, axis=2), -1*n_pitch)  # false if it is a padding time step\n",
        "    mask = tf.cast(mask, tf.float32)\n",
        "    velocity_acc = tf.reduce_mean(mask * tf.square(y_true - y_pred))\n",
        "    return velocity_acc\n",
        "\n",
        "# TODO: Fix Losses\n",
        "bundled_loss = {\n",
        "    'pitch': tf.keras.losses.CategoricalCrossentropy(), \n",
        "    'onset': mse_with_positive_pressure, \n",
        "    'start': mse_with_positive_pressure, \n",
        "    'end': mse_with_positive_pressure, \n",
        "    'velocity': mse_with_positive_pressure,\n",
        "}\n",
        "# TODO: Fix Accuracy\n",
        "bundled_metrics = {\n",
        "    'pitch': pitch_accuracy, \n",
        "    'onset': onset_accuracy, \n",
        "    'start': start_accuracy, \n",
        "    'end': end_accuracy, \n",
        "    'velocity': velocity_accuracy,\n",
        "}\n",
        "optimizer = tf.keras.optimizers.Adam()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "IEEFfGMtuSrk"
      },
      "outputs": [],
      "source": [
        "checkpoint_filepath = './checkpoint'\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgTnwXkVDrq9"
      },
      "source": [
        "## Reinjection Technique"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (None, PIECE_LEN, input_size)\n",
        "sta_shape = (None, 1, input_size)\n",
        "\n",
        "output_shape = (None, PIECE_LEN, target_size)\n",
        "print('n_hidden:', n_hidden)\n",
        "print('input_shape:', input_shape)\n",
        "print('output_shape:', output_shape)\n"
      ],
      "metadata": {
        "id": "C7e-AQp1eQ50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b099d91e-8dbe-435c-9fdc-95dfe364c91b"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_hidden: 100\n",
            "input_shape: (None, 200, 43)\n",
            "output_shape: (None, 200, 57)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAltopwMDqwY",
        "outputId": "3dec0a22-be22-4561-c3e1-37aebba58ff7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer Encoder will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer Decoder will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Building Re-inject Decoder Model: 100%|██████████| 200/200 [00:34<00:00,  5.77it/s]\n"
          ]
        }
      ],
      "source": [
        "from keras import Model\n",
        "from keras import backend as K\n",
        "from keras.layers import Input, Concatenate, Dense, LSTM, Embedding, GRU, Attention, Lambda, Permute, Flatten, BatchNormalization, RepeatVector\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(input_shape[1],input_shape[2]), name='Input_Encoder')\n",
        "encoder = LSTM(n_hidden, activation=tfa.activations.mish, dropout=0.2, recurrent_dropout=0.2, return_sequences=True, return_state=True, name='Encoder')\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "state_h = BatchNormalization(momentum=0.6)(state_h)\n",
        "state_c = BatchNormalization(momentum=0.6)(state_c)\n",
        "states = [state_h, state_c]\n",
        "\n",
        "attention = Attention(n_hidden, name='Attention')\n",
        "attention_bn =BatchNormalization(momentum=0.6, name='BN_Attention')\n",
        "decoder_inputs = Input(shape=(1, target_size), name='Input_Decoder')\n",
        "decoder_lstm = LSTM(n_hidden, activation=tfa.activations.mish, dropout=0.2, recurrent_dropout=0.2, return_sequences=True, return_state=True, name='Decoder')\n",
        "decoder_dense = Dense(target_size, activation=tfa.activations.mish, name='Dense_Timestamp_Output')\n",
        "\n",
        "all_outputs = []\n",
        "all_attention = []\n",
        "dec_input = decoder_inputs\n",
        "for _ in tqdm(range(PIECE_LEN), 'Building Re-inject Decoder Model'):\n",
        "    # Attention Update\n",
        "    context_vector, attention_weights = attention([tf.expand_dims([state_h, state_c],2), encoder_outputs], return_attention_scores=True)\n",
        "    all_attention.append(attention_weights)\n",
        "    context_vector = attention_bn(context_vector) # (2, None, 1, PIECE_LEN)\n",
        "    context_vector_h, context_vector_c = context_vector # (2, None, 1, n_hidden)\n",
        "    context_vector_h = Flatten()(context_vector_h)\n",
        "    context_vector_c = Flatten()(context_vector_c)\n",
        "\n",
        "    state_h = Concatenate(axis=-1, name='Concat_StateH_ContextH')([state_h,context_vector_h])\n",
        "    state_c = Concatenate(axis=-1, name='Concat_StateC_ContextC')([state_c,context_vector_c])\n",
        "    # Decoder Reinject\n",
        "    output_dec, state_h, state_c = decoder_lstm(dec_input, initial_state=states)\n",
        "    # Output\n",
        "    output_dec = decoder_dense(output_dec)\n",
        "    all_outputs.append(output_dec)\n",
        "    # Update Decoder Input & State\n",
        "    dec_input = output_dec\n",
        "    states = [state_h, state_c]\n",
        "\n",
        "# Concatenate all predictions\n",
        "decoder_outputs = Lambda(lambda x: (K.concatenate(x, axis=1)), name='Concat_Timestamp')(all_outputs)\n",
        "pitch_outputs, onset_outputs, start_outputs, end_outputs, velocity_outputs = tf.split(decoder_outputs, [n_pitch, 1, 1, 1, 1], axis=2)\n",
        "decoder_outputs = {\n",
        "    'pitch': pitch_outputs, \n",
        "    'onset': onset_outputs, \n",
        "    'start': start_outputs, \n",
        "    'end': end_outputs, \n",
        "    'velocity': velocity_outputs\n",
        "}\n",
        "\n",
        "\n",
        "# Define and compile model as previously\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\\\n",
        "\n",
        "assert encoder_inputs.shape == input_shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer='rmsprop', \n",
        "    loss=bundled_loss,          # TODO: Fix Losses\n",
        "    # metrics=bundled_metrics,  # TODO: Fix Accuracy\n",
        ")"
      ],
      "metadata": {
        "id": "rQh2VkPIZPNb"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs.element_spec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xX3NXaatxi19",
        "outputId": "31a0db36-cede-4bd4-9812-adc82ab7f84c"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'pitch': TensorSpec(shape=(200, 53), dtype=tf.float32, name=None),\n",
              " 'onset': TensorSpec(shape=(200, 1), dtype=tf.float32, name=None),\n",
              " 'start': TensorSpec(shape=(200, 1), dtype=tf.float32, name=None),\n",
              " 'end': TensorSpec(shape=(200, 1), dtype=tf.float32, name=None),\n",
              " 'velocity': TensorSpec(shape=(200, 1), dtype=tf.float32, name=None)}"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mcRaC8o6eMp",
        "outputId": "d2c97877-ebb5-4388-e185-adba4845630f"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'pitch': <KerasTensor: shape=(None, 200, 53) dtype=float32 (created by layer 'tf.split')>,\n",
              " 'onset': <KerasTensor: shape=(None, 200, 1) dtype=float32 (created by layer 'tf.split')>,\n",
              " 'start': <KerasTensor: shape=(None, 200, 1) dtype=float32 (created by layer 'tf.split')>,\n",
              " 'end': <KerasTensor: shape=(None, 200, 1) dtype=float32 (created by layer 'tf.split')>,\n",
              " 'velocity': <KerasTensor: shape=(None, 200, 1) dtype=float32 (created by layer 'tf.split')>}"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(train_dataset, return_dict=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLB87nVtXNOg",
        "outputId": "c3aa07bb-b55d-46c3-8394-d968e6122ab4"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 74s 148ms/step - loss: 34119870316544.0000 - tf.split_loss: 27191897227264.0000 - tf.split_1_loss: 342791815168.0000 - tf.split_2_loss: -13.1893 - tf.split_3_loss: 931137650688.0000 - tf.split_4_loss: 5654042378240.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': 34119870316544.0,\n",
              " 'tf.split_loss': 27191897227264.0,\n",
              " 'tf.split_1_loss': 342791815168.0,\n",
              " 'tf.split_2_loss': -13.189253807067871,\n",
              " 'tf.split_3_loss': 931137650688.0,\n",
              " 'tf.split_4_loss': 5654042378240.0}"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# masked_loss_function = tf.keras.losses.BinaryFocalCrossentropy(from_logits=True)\n",
        "# masked_loss_function = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "# masked_loss_function = tf.keras.losses.MeanAbsoluteError()"
      ],
      "metadata": {
        "id": "aDRB8dvoZf3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "masked_loss_function"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owAcHzI3arJ9",
        "outputId": "1617d93b-51ca-468f-fd10-c64e2d5904f6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function __main__.masked_loss_function(y_true, y_pred)>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer='rmsprop', \n",
        "    loss=bundled_loss, \n",
        "    loss_weights=1e-30,\n",
        "    metrics=bundled_metrics,\n",
        ")"
      ],
      "metadata": {
        "id": "AEYZQqNUXO2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()\n",
        "tf.keras.utils.plot_model(\n",
        "    model,\n",
        "    to_file='seq2seq_lstm_attention.png',\n",
        "    show_shapes=True,\n",
        "    show_layer_names=True,\n",
        "    rankdir='LR',\n",
        "    expand_nested=False,\n",
        "    dpi=96,\n",
        "    show_layer_activations=True\n",
        ")"
      ],
      "metadata": {
        "id": "qbDBj6j0Zx-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QkqEk-ZYHZu_"
      },
      "outputs": [],
      "source": [
        "model.fit(train_dataset,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=10,\n",
        "        #   validation_split=VALIDATION_RATIO,\n",
        "          verbose=1,\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utf7XJS2phmu"
      },
      "source": [
        "### Predict Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6HB1hWafv_5o"
      },
      "outputs": [],
      "source": [
        "def predict(enc_inputs):\n",
        "    # Init Decoder Input\n",
        "    dec_state = np.zeros((1, target_size))\n",
        "    dec_state[0, start_correction_index] = 1.\n",
        "    all_outputs = []\n",
        "    for enc_input in enc_inputs:\n",
        "        # Format Model Input: (Encoder, Decoder)\n",
        "        format_enc_input = np.expand_dims(enc_input, 0)\n",
        "        format_dec_state = np.expand_dims(dec_state, 0)\n",
        "        # print(format_enc_input.shape)\n",
        "        # print(format_dec_state.shape)\n",
        "\n",
        "        # Model Output\n",
        "        outputs = model.predict([format_enc_input, format_dec_state])\n",
        "        outputs = np.squeeze(outputs)\n",
        "        # print('output:', outputs.shape)\n",
        "        all_outputs.append(np.squeeze(outputs))\n",
        "        dec_state = outputs[-1]\n",
        "        dec_state = np.expand_dims(dec_state, 0)\n",
        "        # print(dec_state.shape)\n",
        "    return np.concatenate(all_outputs, axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoS5QDH90qlQ"
      },
      "source": [
        "# **Midi Format Output**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_dataset(input_dir: str, data_size=-1, batch_per_files=True):\n",
        "    # using tf.data.Dataset API to create dataset\n",
        "    x_paths = [] # input path\n",
        "    y_paths = [] # ans file path\n",
        "    offsets = [] # starting point of a piece\n",
        "    titles = []\n",
        "    data_cnt = 0\n",
        "    for file_name in os.listdir(input_dir): # 'Scan Files'\n",
        "        if data_cnt==data_size-1: break\n",
        "        if file_name.endswith(\".ans.npy\"):\n",
        "            data_cnt+=1\n",
        "            y_path = str(os.path.join(input_dir, file_name))\n",
        "            x_path = str(os.path.join(input_dir, file_name[:-8] + \".npy\"))\n",
        "            assert os.path.exists(x_path), f\"corresponding input file {x_path} doesn't exist\"\n",
        "\n",
        "            # split and pad data into PIECE_LEN\n",
        "            y_content = np.load(y_path)\n",
        "            for offset in range(0, y_content.shape[0], PIECE_LEN):\n",
        "                y_paths.append(y_path)\n",
        "                x_paths.append(x_path)\n",
        "                offsets.append(offset)\n",
        "                titles.append(file_name[:-8])\n",
        "\n",
        "    paths = list(zip(x_paths, y_paths, offsets))\n",
        "    i = 0\n",
        "    while(i < len(paths)): # Batch per Files Handler\n",
        "        dataset = []\n",
        "        temp_dataset = []\n",
        "        flag = False\n",
        "        while(i < len(paths)):\n",
        "            if not batch_per_files:\n",
        "                dataset.append(load_npy_data(*paths[i]))\n",
        "            else:\n",
        "                offset = paths[i][2]\n",
        "                if offset == 0:\n",
        "                    temp_dataset = load_npy_data(*paths[i])\n",
        "                    flag = True\n",
        "                    i += 1\n",
        "                    break\n",
        "                elif flag:\n",
        "                    dataset = []    # Reset Batch\n",
        "                    dataset.append(temp_dataset)\n",
        "                    dataset.append(load_npy_data(*paths[i]))\n",
        "                else:\n",
        "                    dataset.append(load_npy_data(*paths[i]))\n",
        "            i += 1\n",
        "        \n",
        "        # Skip kickstart dataset+\n",
        "        if len(dataset) == 0: continue\n",
        "\n",
        "        # Package\n",
        "        dataset = list(zip(*dataset))\n",
        "        encoder_input_data = np.array(dataset[0])\n",
        "        decoder_input_data = np.array(dataset[1])\n",
        "        decoder_target_data = np.array(dataset[2])\n",
        "        print(encoder_input_data.shape)\n",
        "        print(decoder_input_data.shape)\n",
        "        print(decoder_target_data.shape)\n",
        "\n",
        "        # Shuffle\n",
        "        perm_id = np.random.shuffle(np.arange(encoder_input_data.shape[0]))\n",
        "        encoder_input_data = encoder_input_data[perm_id]\n",
        "        decoder_input_data = decoder_input_data[perm_id]\n",
        "        decoder_target_data = decoder_target_data[perm_id]\n",
        "\n",
        "        yield encoder_input_data, decoder_input_data, decoder_target_data, titles[i-1]\n",
        "    yield encoder_input_data, decoder_input_data, decoder_target_data, titles[-1]"
      ],
      "metadata": {
        "id": "OMRgpOp4AJhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WVMm4rWb19cN"
      },
      "outputs": [],
      "source": [
        "# import midi_np_translation.output2midi as output2midi\n",
        "\n",
        "for test_encoder_input_data, _, _, title in generate_dataset(ROOT+\"/irealpro_dataset_v2\", 5, batch_per_files=True):\n",
        "    test_encoder_input_data = np.reshape(test_encoder_input_data, test_encoder_input_data.shape[1:])\n",
        "    # print(test_encoder_input_data.shape)\n",
        "    print(f'Generating: {title}')\n",
        "    pred_result = predict(test_encoder_input_data)\n",
        "    # output2midi.output_to_midi(bass_ndarr=test_result.reshape(-1,52), ref_midi_path=f\"input_midi/irealpro_transposed/{title}.mid\", output_path=f\"{title}_al.mid\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
