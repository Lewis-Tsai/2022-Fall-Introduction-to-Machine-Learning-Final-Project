{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drcZacjAs_GF",
        "outputId": "4698b1a5-f216-45d2-df59-5349f2d7a0d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow-gpu in /usr/local/lib/python3.8/dist-packages (2.11.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (1.6.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (1.14.1)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (23.1.4)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (2.11.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (3.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (57.4.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (2.11.0)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (2.11.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (0.2.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (1.21.6)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (2.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (4.4.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (1.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (21.3)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (14.0.6)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (1.51.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (3.19.6)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (0.29.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow-gpu) (0.38.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu) (2.25.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu) (2.15.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu) (3.4.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow-gpu) (3.0.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-gpu) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-gpu) (5.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-gpu) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-gpu) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow-gpu) (6.0.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-gpu) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-gpu) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-gpu) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow-gpu) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-gpu) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-gpu) (3.2.2)\n",
            "2.11.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (4.64.1)\n"
          ]
        }
      ],
      "source": [
        "! pip3 install tensorflow-gpu\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "! pip3 install tqdm\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kzNGWq3zuPs"
      },
      "source": [
        "# **Parameter**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMWZqy8YmmEs",
        "outputId": "c2df11d3-3448-4027-e390-b45dde9469bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "WTcqMEfUCkm_"
      },
      "outputs": [],
      "source": [
        "# Original Data Info.\n",
        "n_pitch = 53\n",
        "n_feature = 43\n",
        "\n",
        "# Model Parameter\n",
        "input_size = n_feature\n",
        "target_size = n_pitch + 4 # +4 (addition) is oneset + start correction + end correction + velocity\n",
        "\n",
        "# Training Parameter\n",
        "BATCH_SIZE = 32          # Batch Sizes\n",
        "VALIDATION_RATIO = 0.1  # Validation Ratio to Input Data\n",
        "learning_rate = 0.001   # Learning Rate\n",
        "n_hidden = 2            # Hidden Units number\n",
        "\n",
        "# Data Parameter\n",
        "PIECE_LEN = 200          # (auto set by data) Extra +1 for START timestamp\n",
        "is_onset_index = 53\n",
        "start_correction_index = 54\n",
        "end_correction_index = 55\n",
        "velocity_index = 56\n",
        "\n",
        "ROOT = r'/content/drive/MyDrive/ML'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8iDHeXjo2Zc",
        "outputId": "9c08c092-024e-4b09-cc84-b55817b34778"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ML\n"
          ]
        }
      ],
      "source": [
        "os.chdir(ROOT)\n",
        "print(os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jcLw90VlRmfe"
      },
      "outputs": [],
      "source": [
        "from zipfile import ZipFile\n",
        "# Delete incomplete unzipped folder and run this \n",
        "if 'irealpro_dataset_v2' not in os.listdir():\n",
        "    print('Creating Folder \\'irealpro_dataset_v2\\'')\n",
        "    os.mkdir('../irealpro_dataset_v2')\n",
        "    print('Extract to Folder \\'irealpro_dataset_v2\\'')\n",
        "    with ZipFile(r\"/content/drive/MyDrive/ML/irealpro_dataset_v2.zip\", 'r') as zObject:\n",
        "        zObject.extractall(path=r\"/content/drive/MyDrive/ML/irealpro_dataset_v2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ZmoVUOkVMRUc"
      },
      "outputs": [],
      "source": [
        "np.random.seed(10000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJU0zll_pAsL"
      },
      "source": [
        "# **Data Preparation**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`MAX_DATA`: control how many songs files as the input (assign with -1 to use all songs)"
      ],
      "metadata": {
        "id": "m1xHWMb-HTZ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_DATA = 50"
      ],
      "metadata": {
        "id": "p_vke-NwHoP0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3Tj17ylBnes",
        "outputId": "c7e09c5d-16b7-4b47-ab03-af206d69d5f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "449\n",
            "(1, 449, 200, 43)\n",
            "(1, 449, 1, 57)\n",
            "(1, 449, 200, 57)\n",
            "Data Padded: 49\n",
            "Data with Non Start Decoder Input: 400\n",
            "Data PIECE_LEN: 200\n"
          ]
        }
      ],
      "source": [
        "dec_init_input = np.zeros((1, target_size))\n",
        "dec_init_input[0, start_correction_index] = 1.\n",
        "\n",
        "count_pad = 0 \n",
        "count_spilled = 0\n",
        "def load_npy_data(x_path, y_path, offset):\n",
        "    global count_pad, count_spilled, dec_init_input\n",
        "    x = np.load(x_path)\n",
        "    y = np.load(y_path)\n",
        "\n",
        "    if offset == 0:\n",
        "        Z_ = dec_init_input\n",
        "    else:\n",
        "        Z_ = y[offset-1].astype(np.float32)\n",
        "        Z_ = np.expand_dims(Z_, axis=0)\n",
        "        count_spilled += 1\n",
        "\n",
        "    if x.shape[0] >= offset+PIECE_LEN:\n",
        "        X_ = x[offset:offset+PIECE_LEN].astype(np.float32)\n",
        "        Y_ = y[offset:offset+PIECE_LEN].astype(np.float32)\n",
        "    else:\n",
        "        pad_count = offset + PIECE_LEN - x.shape[0]\n",
        "        X_ = np.pad(x[offset:], ((0, pad_count), (0, 0)), 'constant', constant_values=-1).astype(np.float32)\n",
        "        Y_ = np.pad(y[offset:], ((0, pad_count), (0, 0)), 'constant', constant_values=-1).astype(np.float32)\n",
        "        count_pad += 1\n",
        "    try:\n",
        "        assert X_.shape == (PIECE_LEN, input_size)\n",
        "        assert Z_.shape == (1, target_size)\n",
        "        assert Y_.shape == (PIECE_LEN, target_size)\n",
        "    except:\n",
        "        print('You got',X_.shape, Z_.shape, Y_.shape)\n",
        "        raise ValueError\n",
        "\n",
        "    return X_, Z_, Y_\n",
        "\n",
        "def generate_dataset(input_dir: str, data_size=-1):\n",
        "    # using tf.data.Dataset API to create dataset\n",
        "    x_paths = [] # input path\n",
        "    y_paths = [] # ans file path\n",
        "    offsets = [] # starting point of a piece\n",
        "    data_cnt = 0\n",
        "    for file_name in os.listdir(input_dir): # 'Scan Files'\n",
        "        if data_cnt==data_size-1: break\n",
        "        if file_name.endswith(\".ans.npy\"):\n",
        "            data_cnt+=1\n",
        "            y_path = str(os.path.join(input_dir, file_name))\n",
        "            x_path = str(os.path.join(input_dir, file_name[:-8] + \".npy\"))\n",
        "            assert os.path.exists(x_path), f\"corresponding input file {x_path} doesn't exist\"\n",
        "\n",
        "            # split and pad data into PIECE_LEN\n",
        "            y_content = np.load(y_path)\n",
        "            for offset in range(0, y_content.shape[0], PIECE_LEN):\n",
        "                y_paths.append(y_path)\n",
        "                x_paths.append(x_path)\n",
        "                offsets.append(offset)\n",
        "\n",
        "    dataset = []\n",
        "    for i in zip(x_paths, y_paths, offsets): # 'Read Files'\n",
        "        dataset.append(load_npy_data(*i))\n",
        "    print(len(dataset))\n",
        "    dataset = list(zip(*dataset))\n",
        "    # print(len(dataset[0]))\n",
        "    # print(len(dataset[1]))\n",
        "    # print(len(dataset[2]))\n",
        "    encoder_input_data = np.array(dataset[0])\n",
        "    decoder_input_data = np.array(dataset[1])\n",
        "    decoder_target_data = np.array(dataset[2])\n",
        "    \n",
        "    perm_id = np.random.shuffle(np.arange(encoder_input_data.shape[0]))\n",
        "    encoder_input_data = encoder_input_data[perm_id]\n",
        "    decoder_input_data = decoder_input_data[perm_id]\n",
        "    decoder_target_data = decoder_target_data[perm_id]\n",
        "    \n",
        "    print(encoder_input_data.shape)\n",
        "    print(decoder_input_data.shape)\n",
        "    print(decoder_target_data.shape)\n",
        "\n",
        "    return encoder_input_data, decoder_input_data, decoder_target_data\n",
        "\n",
        "encoder_input_data, decoder_input_data, decoder_target_data = generate_dataset(ROOT+\"/irealpro_dataset_v2\", MAX_DATA)\n",
        "\n",
        "print('Data Padded:', count_pad)\n",
        "print('Data with Non Start Decoder Input:', count_spilled)\n",
        "print('Data PIECE_LEN:', PIECE_LEN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1rw5ZzmBeZZ6"
      },
      "outputs": [],
      "source": [
        "# np.save(ROOT + '/encoder_input_data.npy', encoder_input_data)\n",
        "# np.save(ROOT + '/decoder_input_data.npy', decoder_input_data)\n",
        "# np.save(ROOT + '/decoder_target_data.npy', decoder_target_data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# encoder_input_data = np.load(ROOT + '/encoder_input_data.npy', allow_pickle=True)\n",
        "# decoder_input_data = np.load(ROOT + '/decoder_input_data.npy', allow_pickle=True)\n",
        "# decoder_target_data = np.load(ROOT + '/decoder_target_data.npy', allow_pickle=True)"
      ],
      "metadata": {
        "id": "2sDGfGtXsSEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysk_4cPxhPJw"
      },
      "source": [
        "# **Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EN1ooFJHhGvt"
      },
      "source": [
        "## *Define Loss, Accuracy, and Optimizer*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "Jqzuy9Z9rTRj"
      },
      "outputs": [],
      "source": [
        "# Define Loss, Accuracy, and Optimizer\n",
        "def masked_loss_function(y_true, y_pred):\n",
        "    mask = tf.math.not_equal(tf.reduce_sum(y_true[:,:,:n_pitch], axis=2), -1*n_pitch)  # false if it is a padding time step\n",
        "    pitch_loss = tf.losses.categorical_crossentropy(y_true[:,:,:n_pitch], y_pred[:,:,:n_pitch])\n",
        "    onset_loss = tf.losses.binary_crossentropy(y_true[:,:,n_pitch:n_pitch+1], y_pred[:,:,n_pitch:n_pitch+1])\n",
        "    start_loss = tf.square(y_true[:,:,n_pitch+1] - y_pred[:,:,n_pitch+1])\n",
        "    end_loss = tf.square(y_true[:,:,n_pitch+2] - y_pred[:,:,n_pitch+2])\n",
        "    velocity_loss = tf.square(y_true[:,:,n_pitch+3] - y_pred[:,:,n_pitch+3])\n",
        "    total_loss = tf.reduce_sum([pitch_loss, onset_loss, start_loss, end_loss, velocity_loss], axis=0)\n",
        "    total_loss *= tf.cast(mask, total_loss.dtype)\n",
        "    return tf.reduce_mean(total_loss)\n",
        "\n",
        "def masked_accuracy(y_true, y_pred):\n",
        "    mask = tf.math.not_equal(tf.reduce_sum(y_true[:,:,:n_pitch], axis=2), -1*n_pitch)  # false if it is a padding time step\n",
        "    mask = tf.cast(mask, tf.float32)\n",
        "    pitch_acc = tf.reduce_mean(mask * tf.metrics.categorical_accuracy(y_true[:,:,:n_pitch], y_pred[:,:,:n_pitch]))\n",
        "    onset_acc = tf.reduce_mean(mask * tf.metrics.binary_accuracy(y_true[:,:,n_pitch:n_pitch+1], y_pred[:,:,n_pitch:n_pitch+1]))\n",
        "    start_loss = tf.reduce_mean(mask * tf.square(y_true[:,:,n_pitch+1] - y_pred[:,:,n_pitch+1]))\n",
        "    end_loss = tf.reduce_mean(mask * tf.square(y_true[:,:,n_pitch+2] - y_pred[:,:,n_pitch+2]))\n",
        "    velocity_loss = tf.reduce_mean(mask * tf.square(y_true[:,:,n_pitch+3] - y_pred[:,:,n_pitch+3]))\n",
        "\n",
        "    return pitch_acc, onset_acc, start_loss, end_loss, velocity_loss\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "IEEFfGMtuSrk"
      },
      "outputs": [],
      "source": [
        "checkpoint_filepath = './checkpoint'\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgTnwXkVDrq9"
      },
      "source": [
        "## Reinjection Technique"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAltopwMDqwY",
        "outputId": "c178543a-9370-4d28-e43e-9a22627d53f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [01:06<00:00,  3.02it/s]\n"
          ]
        }
      ],
      "source": [
        "from keras import Model\n",
        "from keras import backend as K\n",
        "from keras.layers import Input, Concatenate, Dense, LSTM, Embedding, GRU, Attention, Lambda, Permute, Flatten\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(PIECE_LEN, input_size), name='Input_Encoder')\n",
        "encoder = LSTM(n_hidden, return_sequences=True, return_state=True, name='Encoder')\n",
        "\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "states = [state_h, state_c]\n",
        "\n",
        "attention = Attention(n_hidden, name='Attention')\n",
        "\n",
        "decoder_inputs = Input(shape=(1, target_size), name='Input_Decoder')\n",
        "decoder_lstm = LSTM(n_hidden, return_sequences=True, return_state=True, name='Decoder')\n",
        "decoder_dense = Dense(target_size, activation='softmax', name='Dense_Timestamp_Output')\n",
        "\n",
        "all_outputs = []\n",
        "all_attention = []\n",
        "inputs = decoder_inputs\n",
        "for _ in tqdm(range(PIECE_LEN)):\n",
        "    # Attention Update\n",
        "    # print(states.shape) \n",
        "    # print(encoder_outputs.shape)\n",
        "    context_vector, attention_weights = attention([tf.expand_dims([state_h, state_c],1), encoder_outputs], return_attention_scores=True)\n",
        "    all_attention.append(attention_weights)\n",
        "    # context_vector = Permute((2, 1))(context_vector)\n",
        "    # context_vector = Flatten()(context_vector)\n",
        "    # print(inputs.shape)\n",
        "    # print(context_vector.shape)\n",
        "    context_vector_h, context_vector_c = Lambda(lambda x: x[:,0,:,:], output_shape=(1,) + context_vector.shape[2:], name='Split_Context')(context_vector)\n",
        "    # print(context_vector_h.shape)\n",
        "    # print(context_vector_c.shape)\n",
        "    state_h = Concatenate(axis=-1, name='Concat_StateH_ContextH')([state_h,context_vector_h])\n",
        "    state_c = Concatenate(axis=-1, name='Concat_StateC_ContextC')([state_c,context_vector_c])\n",
        "    # Decoder Reinject\n",
        "    outputs, state_h, state_c = decoder_lstm(inputs, initial_state=states)\n",
        "    # Output\n",
        "    outputs = decoder_dense(outputs)\n",
        "    all_outputs.append(outputs)\n",
        "    # Update Decoder Input & State\n",
        "    inputs = outputs\n",
        "    states = [state_h, state_c]\n",
        "\n",
        "# Concatenate all predictions\n",
        "decoder_outputs = Lambda(lambda x: K.concatenate(x, axis=1), name='Concat_Output')(all_outputs)\n",
        "\n",
        "# Define and compile model as previously\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='rmsprop', \n",
        "              loss=masked_loss_function, \n",
        "            #   metrics={masked_accuracy},\n",
        "              )"
      ],
      "metadata": {
        "id": "rQh2VkPIZPNb"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()\n",
        "tf.keras.utils.plot_model(\n",
        "    model,\n",
        "    to_file='seq2seq_lstm_attention.png',\n",
        "    show_shapes=True,\n",
        "    show_layer_names=True,\n",
        "    rankdir='LR',\n",
        "    expand_nested=False,\n",
        "    dpi=96,\n",
        "    show_layer_activations=True\n",
        ")"
      ],
      "metadata": {
        "id": "qbDBj6j0Zx-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "QkqEk-ZYHZu_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da8335e0-adfe-42aa-eb09-9547454a87ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(449, 200, 43)\n",
            "(449, 1, 57)\n",
            "(449, 200, 57)\n",
            "Epoch 1/10\n",
            "15/15 [==============================] - 382s 266ms/step - loss: 10201.8428\n",
            "Epoch 2/10\n",
            "15/15 [==============================] - 5s 357ms/step - loss: 10201.6650\n",
            "Epoch 3/10\n",
            "15/15 [==============================] - 4s 268ms/step - loss: 10201.4814\n",
            "Epoch 4/10\n",
            "15/15 [==============================] - 4s 270ms/step - loss: 10201.2676\n",
            "Epoch 5/10\n",
            "15/15 [==============================] - 4s 267ms/step - loss: 10201.0176\n",
            "Epoch 6/10\n",
            "15/15 [==============================] - 4s 263ms/step - loss: 10200.7197\n",
            "Epoch 7/10\n",
            "15/15 [==============================] - 4s 280ms/step - loss: 10200.3633\n",
            "Epoch 8/10\n",
            "15/15 [==============================] - 4s 297ms/step - loss: 10199.9355\n",
            "Epoch 9/10\n",
            "15/15 [==============================] - 4s 294ms/step - loss: 10199.4189\n",
            "Epoch 10/10\n",
            "15/15 [==============================] - 4s 299ms/step - loss: 10198.7998\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc87a57b940>"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ],
      "source": [
        "print(encoder_input_data.shape)\n",
        "print(decoder_input_data.shape)\n",
        "print(decoder_target_data.shape)\n",
        "\n",
        "if encoder_input_data.shape[0] == 1:\n",
        "    encoder_input_data = tf.reshape(encoder_input_data, encoder_input_data.shape[1:])\n",
        "    decoder_input_data = tf.reshape(decoder_input_data, decoder_input_data.shape[1:])\n",
        "    decoder_target_data = tf.reshape(decoder_target_data, decoder_target_data.shape[1:])\n",
        "    print(encoder_input_data.shape)\n",
        "    print(decoder_input_data.shape)\n",
        "    print(decoder_target_data.shape)\n",
        "\n",
        "inputs = tf.data.Dataset.zip(tuple([tf.data.Dataset.from_tensor_slices((encoder_input_data)), tf.data.Dataset.from_tensor_slices((decoder_input_data))]))\n",
        "outputs = tf.data.Dataset.from_tensor_slices((decoder_target_data))\n",
        "\n",
        "train_dataset = tf.data.Dataset.zip((inputs, outputs))\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE).prefetch(10)\n",
        "\n",
        "model.fit(train_dataset,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=10,\n",
        "          verbose=1,\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utf7XJS2phmu"
      },
      "source": [
        "### Predict Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "6HB1hWafv_5o"
      },
      "outputs": [],
      "source": [
        "def predict(enc_inputs):\n",
        "    # Init Decoder Input\n",
        "    dec_state = np.zeros((1, target_size))\n",
        "    dec_state[0, start_correction_index] = 1.\n",
        "    all_outputs = []\n",
        "    for enc_input in enc_inputs:\n",
        "        # Format Model Input: (Encoder, Decoder)\n",
        "        format_enc_input = np.expand_dims(enc_input, 0)\n",
        "        format_dec_state = np.expand_dims(dec_state, 0)\n",
        "        # print(format_enc_input.shape)\n",
        "        # print(format_dec_state.shape)\n",
        "\n",
        "        # Model Output\n",
        "        outputs = model.predict([format_enc_input, format_dec_state])\n",
        "        outputs = np.squeeze(outputs)\n",
        "        # print('output:', outputs.shape)\n",
        "        all_outputs.append(np.squeeze(outputs))\n",
        "        dec_state = outputs[-1]\n",
        "        dec_state = np.expand_dims(dec_state, 0)\n",
        "        # print(dec_state.shape)\n",
        "    return np.concatenate(all_outputs, axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoS5QDH90qlQ"
      },
      "source": [
        "# **Midi Format Output**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_dataset(input_dir: str, data_size=-1, batch_per_files=True):\n",
        "    # using tf.data.Dataset API to create dataset\n",
        "    x_paths = [] # input path\n",
        "    y_paths = [] # ans file path\n",
        "    offsets = [] # starting point of a piece\n",
        "    titles = []\n",
        "    data_cnt = 0\n",
        "    for file_name in os.listdir(input_dir): # 'Scan Files'\n",
        "        if data_cnt==data_size-1: break\n",
        "        if file_name.endswith(\".ans.npy\"):\n",
        "            data_cnt+=1\n",
        "            y_path = str(os.path.join(input_dir, file_name))\n",
        "            x_path = str(os.path.join(input_dir, file_name[:-8] + \".npy\"))\n",
        "            assert os.path.exists(x_path), f\"corresponding input file {x_path} doesn't exist\"\n",
        "\n",
        "            # split and pad data into PIECE_LEN\n",
        "            y_content = np.load(y_path)\n",
        "            for offset in range(0, y_content.shape[0], PIECE_LEN):\n",
        "                y_paths.append(y_path)\n",
        "                x_paths.append(x_path)\n",
        "                offsets.append(offset)\n",
        "                titles.append(file_name[:-8])\n",
        "\n",
        "    paths = list(zip(x_paths, y_paths, offsets))\n",
        "    i = 0\n",
        "    while(i < len(paths)): # Batch per Files Handler\n",
        "        dataset = []\n",
        "        temp_dataset = []\n",
        "        flag = False\n",
        "        while(i < len(paths)):\n",
        "            if not batch_per_files:\n",
        "                dataset.append(load_npy_data(*paths[i]))\n",
        "            else:\n",
        "                offset = paths[i][2]\n",
        "                if offset == 0:\n",
        "                    temp_dataset = load_npy_data(*paths[i])\n",
        "                    flag = True\n",
        "                    i += 1\n",
        "                    break\n",
        "                elif flag:\n",
        "                    dataset = []    # Reset Batch\n",
        "                    dataset.append(temp_dataset)\n",
        "                    dataset.append(load_npy_data(*paths[i]))\n",
        "                else:\n",
        "                    dataset.append(load_npy_data(*paths[i]))\n",
        "            i += 1\n",
        "        \n",
        "        # Skip kickstart dataset+\n",
        "        if len(dataset) == 0: continue\n",
        "\n",
        "        # Package\n",
        "        dataset = list(zip(*dataset))\n",
        "        encoder_input_data = np.array(dataset[0])\n",
        "        decoder_input_data = np.array(dataset[1])\n",
        "        decoder_target_data = np.array(dataset[2])\n",
        "        print(encoder_input_data.shape)\n",
        "        print(decoder_input_data.shape)\n",
        "        print(decoder_target_data.shape)\n",
        "\n",
        "        # Shuffle\n",
        "        perm_id = np.random.shuffle(np.arange(encoder_input_data.shape[0]))\n",
        "        encoder_input_data = encoder_input_data[perm_id]\n",
        "        decoder_input_data = decoder_input_data[perm_id]\n",
        "        decoder_target_data = decoder_target_data[perm_id]\n",
        "\n",
        "        yield encoder_input_data, decoder_input_data, decoder_target_data, titles[i-1]\n",
        "    yield encoder_input_data, decoder_input_data, decoder_target_data, titles[-1]"
      ],
      "metadata": {
        "id": "OMRgpOp4AJhh"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "WVMm4rWb19cN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7ecb987-a5b1-4544-b402-193bbc71bddf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(11, 200, 43)\n",
            "(11, 1, 57)\n",
            "(11, 200, 57)\n",
            "Generating: I Hear Music_d1.mid\n",
            "1/1 [==============================] - 0s 80ms/step\n",
            "1/1 [==============================] - 0s 80ms/step\n",
            "1/1 [==============================] - 0s 80ms/step\n",
            "1/1 [==============================] - 0s 81ms/step\n",
            "1/1 [==============================] - 0s 106ms/step\n",
            "1/1 [==============================] - 0s 83ms/step\n",
            "1/1 [==============================] - 0s 80ms/step\n",
            "1/1 [==============================] - 0s 90ms/step\n",
            "1/1 [==============================] - 0s 83ms/step\n",
            "1/1 [==============================] - 0s 87ms/step\n",
            "1/1 [==============================] - 0s 77ms/step\n",
            "(8, 200, 43)\n",
            "(8, 1, 57)\n",
            "(8, 200, 57)\n",
            "Generating: If I Should Lose You_d3.mid\n",
            "1/1 [==============================] - 0s 82ms/step\n",
            "1/1 [==============================] - 0s 82ms/step\n",
            "1/1 [==============================] - 0s 82ms/step\n",
            "1/1 [==============================] - 0s 90ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 79ms/step\n",
            "(7, 200, 43)\n",
            "(7, 1, 57)\n",
            "(7, 200, 57)\n",
            "Generating: If I Should Lose You_p3.mid\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "(7, 200, 43)\n",
            "(7, 1, 57)\n",
            "(7, 200, 57)\n",
            "Generating: If I Should Lose You_p3.mid\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "Generating: If I Should Lose You_p3.mid\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 77ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n"
          ]
        }
      ],
      "source": [
        "# import midi_np_translation.output2midi as output2midi\n",
        "\n",
        "for test_encoder_input_data, _, _, title in generate_dataset(ROOT+\"/irealpro_dataset_v2\", 5, batch_per_files=True):\n",
        "    test_encoder_input_data = np.reshape(test_encoder_input_data, test_encoder_input_data.shape[1:])\n",
        "    # print(test_encoder_input_data.shape)\n",
        "    print(f'Generating: {title}')\n",
        "    pred_result = predict(test_encoder_input_data)\n",
        "    # output2midi.output_to_midi(bass_ndarr=test_result.reshape(-1,52), ref_midi_path=f\"input_midi/irealpro_transposed/{title}.mid\", output_path=f\"{title}_al.mid\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
